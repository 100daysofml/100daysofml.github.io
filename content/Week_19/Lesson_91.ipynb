{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lesson 91: Federated Learning Fundamentals\n",
    "\n",
    "## Introduction\n",
    "\n",
    "**Federated Learning** is a revolutionary machine learning paradigm that enables training models across multiple decentralized devices or servers holding local data samples, without exchanging the raw data itself. This approach addresses critical challenges in modern machine learning:\n",
    "\n",
    "### Why Federated Learning?\n",
    "\n",
    "1. **Privacy Preservation**: Raw data never leaves the device, protecting sensitive user information\n",
    "2. **Regulatory Compliance**: Meets GDPR, HIPAA, and other data protection requirements\n",
    "3. **Data Silos**: Enables collaboration across organizations without data sharing\n",
    "4. **Edge Computing**: Leverages computational power of edge devices (smartphones, IoT devices)\n",
    "5. **Network Efficiency**: Reduces bandwidth by transmitting model updates instead of raw data\n",
    "\n",
    "### Real-World Applications\n",
    "\n",
    "- **Mobile Keyboards**: Google's Gboard uses federated learning to improve next-word prediction\n",
    "- **Healthcare**: Training diagnostic models across hospitals without sharing patient data\n",
    "- **Finance**: Fraud detection across banks while maintaining customer privacy\n",
    "- **IoT**: Smart home devices learning user preferences locally\n",
    "\n",
    "### Learning Objectives\n",
    "\n",
    "By the end of this lesson, you will:\n",
    "- Understand the architecture and workflow of federated learning systems\n",
    "- Implement the Federated Averaging (FedAvg) algorithm\n",
    "- Compare centralized vs. federated learning performance\n",
    "- Recognize challenges: communication costs, non-IID data, and convergence\n",
    "- Build a practical federated learning simulation with multiple clients"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Core Concepts and Theory\n",
    "\n",
    "### Federated Learning Architecture\n",
    "\n",
    "Federated learning involves three key components:\n",
    "\n",
    "1. **Central Server**: Coordinates training and aggregates model updates\n",
    "2. **Clients (Participants)**: Local devices/servers with private data\n",
    "3. **Communication Protocol**: Secure channels for model parameter exchange\n",
    "\n",
    "### The Federated Averaging (FedAvg) Algorithm\n",
    "\n",
    "Proposed by McMahan et al. (2017), FedAvg is the foundational algorithm for federated learning.\n",
    "\n",
    "#### Algorithm Steps:\n",
    "\n",
    "**Server Side:**\n",
    "1. Initialize global model with parameters $w_0$\n",
    "2. For each round $t = 1, 2, \\ldots, T$:\n",
    "   - Select a subset of $K$ clients (out of $N$ total)\n",
    "   - Send current global model $w_t$ to selected clients\n",
    "   - Wait for client updates\n",
    "   - Aggregate updates using weighted average\n",
    "\n",
    "**Client Side (each client $k$):**\n",
    "1. Receive global model $w_t$ from server\n",
    "2. Train on local data for $E$ epochs\n",
    "3. Compute updated model $w_k^{t+1}$\n",
    "4. Send $w_k^{t+1}$ back to server\n",
    "\n",
    "#### Mathematical Foundation\n",
    "\n",
    "The global model update is computed as a weighted average of client models:\n",
    "\n",
    "$$\n",
    "w_{t+1} = \\sum_{k=1}^{K} \\frac{n_k}{n} w_k^{t+1}\n",
    "$$\n",
    "\n",
    "Where:\n",
    "- $w_{t+1}$ = new global model parameters\n",
    "- $w_k^{t+1}$ = updated model from client $k$\n",
    "- $n_k$ = number of training samples on client $k$\n",
    "- $n = \\sum_{k=1}^{K} n_k$ = total samples across selected clients\n",
    "\n",
    "#### Objective Function\n",
    "\n",
    "Federated learning minimizes the global loss:\n",
    "\n",
    "$$\n",
    "\\min_{w} f(w) = \\sum_{k=1}^{N} \\frac{n_k}{n_{\\text{total}}} F_k(w)\n",
    "$$\n",
    "\n",
    "Where:\n",
    "- $F_k(w) = \\frac{1}{n_k} \\sum_{i \\in \\mathcal{D}_k} \\ell(x_i, y_i; w)$ is the local loss on client $k$'s data $\\mathcal{D}_k$\n",
    "- $\\ell(x_i, y_i; w)$ is the loss function for sample $(x_i, y_i)$\n",
    "\n",
    "### Key Challenges\n",
    "\n",
    "1. **Communication Costs**: Frequent model exchanges can be expensive\n",
    "2. **Non-IID Data**: Client data distributions may differ significantly\n",
    "3. **System Heterogeneity**: Varying computational capabilities across clients\n",
    "4. **Privacy Guarantees**: Model updates can still leak information\n",
    "5. **Convergence**: Slower and less stable than centralized training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Practical Implementation\n",
    "\n",
    "Let's implement a federated learning system from scratch using PyTorch. We'll simulate multiple clients training on the MNIST dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from copy import deepcopy\n",
    "import random\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "random.seed(42)\n",
    "\n",
    "print(\"Libraries imported successfully!\")\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"Device: {'cuda' if torch.cuda.is_available() else 'cpu'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the Neural Network Model\n",
    "\n",
    "We'll use a simple CNN for MNIST digit classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleCNN(nn.Module):\n",
    "    \"\"\"Simple CNN for MNIST classification\"\"\"\n",
    "    def __init__(self):\n",
    "        super(SimpleCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, 3, 1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, 3, 1)\n",
    "        self.dropout1 = nn.Dropout2d(0.25)\n",
    "        self.dropout2 = nn.Dropout2d(0.5)\n",
    "        self.fc1 = nn.Linear(9216, 128)\n",
    "        self.fc2 = nn.Linear(128, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = torch.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = torch.relu(x)\n",
    "        x = torch.max_pool2d(x, 2)\n",
    "        x = self.dropout1(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc1(x)\n",
    "        x = torch.relu(x)\n",
    "        x = self.dropout2(x)\n",
    "        x = self.fc2(x)\n",
    "        return torch.log_softmax(x, dim=1)\n",
    "\n",
    "# Initialize model\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = SimpleCNN().to(device)\n",
    "print(f\"Model architecture:\\n{model}\")\n",
    "print(f\"\\nTotal parameters: {sum(p.numel() for p in model.parameters())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load and Partition MNIST Dataset\n",
    "\n",
    "We'll split the training data among multiple clients to simulate federated learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load MNIST dataset\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.1307,), (0.3081,))\n",
    "])\n",
    "\n",
    "train_dataset = torchvision.datasets.MNIST(\n",
    "    root='./data', train=True, download=True, transform=transform\n",
    ")\n",
    "test_dataset = torchvision.datasets.MNIST(\n",
    "    root='./data', train=False, download=True, transform=transform\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(test_dataset, batch_size=1000, shuffle=False)\n",
    "\n",
    "print(f\"Total training samples: {len(train_dataset)}\")\n",
    "print(f\"Total test samples: {len(test_dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_client_datasets(dataset, num_clients, iid=True):\n",
    "    \"\"\"\n",
    "    Partition dataset among clients.\n",
    "    \n",
    "    Args:\n",
    "        dataset: PyTorch dataset\n",
    "        num_clients: Number of federated clients\n",
    "        iid: If True, distribute data uniformly (IID)\n",
    "             If False, create non-IID distribution (each client gets only 2 digits)\n",
    "    \n",
    "    Returns:\n",
    "        List of client datasets\n",
    "    \"\"\"\n",
    "    if iid:\n",
    "        # IID: Randomly shuffle and split equally\n",
    "        num_items = len(dataset) // num_clients\n",
    "        client_datasets = []\n",
    "        all_indices = list(range(len(dataset)))\n",
    "        random.shuffle(all_indices)\n",
    "        \n",
    "        for i in range(num_clients):\n",
    "            start = i * num_items\n",
    "            end = start + num_items if i < num_clients - 1 else len(dataset)\n",
    "            indices = all_indices[start:end]\n",
    "            client_datasets.append(Subset(dataset, indices))\n",
    "    else:\n",
    "        # Non-IID: Each client gets data from only 2 digit classes\n",
    "        # Group indices by label\n",
    "        label_indices = {i: [] for i in range(10)}\n",
    "        for idx, (_, label) in enumerate(dataset):\n",
    "            label_indices[label].append(idx)\n",
    "        \n",
    "        client_datasets = []\n",
    "        digits_per_client = 2\n",
    "        \n",
    "        for i in range(num_clients):\n",
    "            # Assign 2 consecutive digits to each client (with wrap-around)\n",
    "            client_labels = [(i * digits_per_client + j) % 10 for j in range(digits_per_client)]\n",
    "            client_indices = []\n",
    "            \n",
    "            for label in client_labels:\n",
    "                client_indices.extend(label_indices[label])\n",
    "            \n",
    "            random.shuffle(client_indices)\n",
    "            client_datasets.append(Subset(dataset, client_indices))\n",
    "    \n",
    "    return client_datasets\n",
    "\n",
    "# Create client datasets (IID distribution)\n",
    "NUM_CLIENTS = 5\n",
    "client_datasets = create_client_datasets(train_dataset, NUM_CLIENTS, iid=True)\n",
    "\n",
    "print(f\"\\nCreated {NUM_CLIENTS} client datasets (IID):\")\n",
    "for i, dataset in enumerate(client_datasets):\n",
    "    print(f\"  Client {i+1}: {len(dataset)} samples\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implement Client Training Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def client_update(client_model, client_dataset, epochs=1, batch_size=32, lr=0.01):\n",
    "    \"\"\"\n",
    "    Train model on client's local data.\n",
    "    \n",
    "    Args:\n",
    "        client_model: Model to train\n",
    "        client_dataset: Client's local dataset\n",
    "        epochs: Number of local training epochs\n",
    "        batch_size: Batch size for training\n",
    "        lr: Learning rate\n",
    "    \n",
    "    Returns:\n",
    "        Updated model state dict and number of samples\n",
    "    \"\"\"\n",
    "    client_model.train()\n",
    "    criterion = nn.NLLLoss()\n",
    "    optimizer = optim.SGD(client_model.parameters(), lr=lr)\n",
    "    \n",
    "    dataloader = DataLoader(client_dataset, batch_size=batch_size, shuffle=True)\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        for data, target in dataloader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            output = client_model(data)\n",
    "            loss = criterion(output, target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "    \n",
    "    return client_model.state_dict(), len(client_dataset)\n",
    "\n",
    "print(\"Client training function defined successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implement Federated Averaging (FedAvg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def federated_averaging(global_model, client_models, client_weights):\n",
    "    \"\"\"\n",
    "    Aggregate client models using weighted averaging.\n",
    "    \n",
    "    Args:\n",
    "        global_model: Global model to update\n",
    "        client_models: List of client model state dicts\n",
    "        client_weights: List of client dataset sizes\n",
    "    \n",
    "    Returns:\n",
    "        Updated global model\n",
    "    \"\"\"\n",
    "    global_dict = global_model.state_dict()\n",
    "    total_samples = sum(client_weights)\n",
    "    \n",
    "    # Initialize with zeros\n",
    "    for key in global_dict.keys():\n",
    "        global_dict[key] = torch.zeros_like(global_dict[key], dtype=torch.float32)\n",
    "    \n",
    "    # Weighted average of client parameters\n",
    "    for client_model, weight in zip(client_models, client_weights):\n",
    "        for key in global_dict.keys():\n",
    "            global_dict[key] += client_model[key] * (weight / total_samples)\n",
    "    \n",
    "    global_model.load_state_dict(global_dict)\n",
    "    return global_model\n",
    "\n",
    "print(\"Federated averaging function defined successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, test_loader):\n",
    "    \"\"\"\n",
    "    Evaluate model on test dataset.\n",
    "    \n",
    "    Returns:\n",
    "        Test accuracy and loss\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    criterion = nn.NLLLoss()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            test_loss += criterion(output, target).item()\n",
    "            pred = output.argmax(dim=1, keepdim=True)\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "    \n",
    "    test_loss /= len(test_loader)\n",
    "    accuracy = 100. * correct / len(test_loader.dataset)\n",
    "    \n",
    "    return accuracy, test_loss\n",
    "\n",
    "print(\"Evaluation function defined successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run Federated Learning Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def federated_learning(num_rounds=10, local_epochs=1, client_fraction=1.0):\n",
    "    \"\"\"\n",
    "    Execute federated learning training.\n",
    "    \n",
    "    Args:\n",
    "        num_rounds: Number of communication rounds\n",
    "        local_epochs: Number of local training epochs per client\n",
    "        client_fraction: Fraction of clients to select each round\n",
    "    \n",
    "    Returns:\n",
    "        Training history (accuracies and losses)\n",
    "    \"\"\"\n",
    "    # Initialize global model\n",
    "    global_model = SimpleCNN().to(device)\n",
    "    \n",
    "    history = {'accuracy': [], 'loss': []}\n",
    "    \n",
    "    for round_num in range(num_rounds):\n",
    "        print(f\"\\n{'='*50}\")\n",
    "        print(f\"Communication Round {round_num + 1}/{num_rounds}\")\n",
    "        print(f\"{'='*50}\")\n",
    "        \n",
    "        # Select clients for this round\n",
    "        num_selected = max(1, int(NUM_CLIENTS * client_fraction))\n",
    "        selected_clients = random.sample(range(NUM_CLIENTS), num_selected)\n",
    "        print(f\"Selected clients: {[c+1 for c in selected_clients]}\")\n",
    "        \n",
    "        # Train on selected clients\n",
    "        client_models = []\n",
    "        client_weights = []\n",
    "        \n",
    "        for client_id in selected_clients:\n",
    "            # Create client model copy\n",
    "            client_model = SimpleCNN().to(device)\n",
    "            client_model.load_state_dict(global_model.state_dict())\n",
    "            \n",
    "            # Train on client's data\n",
    "            state_dict, num_samples = client_update(\n",
    "                client_model, \n",
    "                client_datasets[client_id],\n",
    "                epochs=local_epochs\n",
    "            )\n",
    "            \n",
    "            client_models.append(state_dict)\n",
    "            client_weights.append(num_samples)\n",
    "            print(f\"  Client {client_id+1} trained on {num_samples} samples\")\n",
    "        \n",
    "        # Aggregate client models\n",
    "        global_model = federated_averaging(global_model, client_models, client_weights)\n",
    "        print(\"  Global model updated via FedAvg\")\n",
    "        \n",
    "        # Evaluate global model\n",
    "        accuracy, loss = evaluate(global_model, test_loader)\n",
    "        history['accuracy'].append(accuracy)\n",
    "        history['loss'].append(loss)\n",
    "        \n",
    "        print(f\"\\n  Test Accuracy: {accuracy:.2f}%\")\n",
    "        print(f\"  Test Loss: {loss:.4f}\")\n",
    "    \n",
    "    return global_model, history\n",
    "\n",
    "# Run federated learning\n",
    "NUM_ROUNDS = 10\n",
    "LOCAL_EPOCHS = 2\n",
    "\n",
    "print(f\"\\nStarting Federated Learning...\")\n",
    "print(f\"Configuration:\")\n",
    "print(f\"  - Number of clients: {NUM_CLIENTS}\")\n",
    "print(f\"  - Communication rounds: {NUM_ROUNDS}\")\n",
    "print(f\"  - Local epochs per round: {LOCAL_EPOCHS}\")\n",
    "\n",
    "fed_model, fed_history = federated_learning(\n",
    "    num_rounds=NUM_ROUNDS,\n",
    "    local_epochs=LOCAL_EPOCHS,\n",
    "    client_fraction=1.0\n",
    ")\n",
    "\n",
    "print(f\"\\n{'='*50}\")\n",
    "print(\"Federated Learning Complete!\")\n",
    "print(f\"Final Test Accuracy: {fed_history['accuracy'][-1]:.2f}%\")\n",
    "print(f\"{'='*50}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparison: Centralized vs. Federated Learning\n",
    "\n",
    "Let's compare federated learning with traditional centralized training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def centralized_training(num_epochs=10, batch_size=32, lr=0.01):\n",
    "    \"\"\"\n",
    "    Traditional centralized training on entire dataset.\n",
    "    \"\"\"\n",
    "    central_model = SimpleCNN().to(device)\n",
    "    criterion = nn.NLLLoss()\n",
    "    optimizer = optim.SGD(central_model.parameters(), lr=lr)\n",
    "    \n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    \n",
    "    history = {'accuracy': [], 'loss': []}\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        central_model.train()\n",
    "        for data, target in train_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            output = central_model(data)\n",
    "            loss = criterion(output, target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        \n",
    "        # Evaluate\n",
    "        accuracy, loss = evaluate(central_model, test_loader)\n",
    "        history['accuracy'].append(accuracy)\n",
    "        history['loss'].append(loss)\n",
    "        \n",
    "        print(f\"Epoch {epoch+1}/{num_epochs} - Accuracy: {accuracy:.2f}%, Loss: {loss:.4f}\")\n",
    "    \n",
    "    return central_model, history\n",
    "\n",
    "print(\"\\nStarting Centralized Training...\\n\")\n",
    "central_model, central_history = centralized_training(\n",
    "    num_epochs=NUM_ROUNDS,\n",
    "    batch_size=32,\n",
    "    lr=0.01\n",
    ")\n",
    "\n",
    "print(f\"\\nCentralized Training Complete!\")\n",
    "print(f\"Final Test Accuracy: {central_history['accuracy'][-1]:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize Training Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Plot accuracy\n",
    "ax1.plot(range(1, NUM_ROUNDS + 1), fed_history['accuracy'], \n",
    "         marker='o', label='Federated Learning', linewidth=2)\n",
    "ax1.plot(range(1, NUM_ROUNDS + 1), central_history['accuracy'], \n",
    "         marker='s', label='Centralized Learning', linewidth=2)\n",
    "ax1.set_xlabel('Round / Epoch', fontsize=12)\n",
    "ax1.set_ylabel('Test Accuracy (%)', fontsize=12)\n",
    "ax1.set_title('Accuracy Comparison', fontsize=14, fontweight='bold')\n",
    "ax1.legend(fontsize=10)\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Plot loss\n",
    "ax2.plot(range(1, NUM_ROUNDS + 1), fed_history['loss'], \n",
    "         marker='o', label='Federated Learning', linewidth=2)\n",
    "ax2.plot(range(1, NUM_ROUNDS + 1), central_history['loss'], \n",
    "         marker='s', label='Centralized Learning', linewidth=2)\n",
    "ax2.set_xlabel('Round / Epoch', fontsize=12)\n",
    "ax2.set_ylabel('Test Loss', fontsize=12)\n",
    "ax2.set_title('Loss Comparison', fontsize=14, fontweight='bold')\n",
    "ax2.legend(fontsize=10)\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('federated_vs_centralized.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nKey Observations:\")\n",
    "print(f\"  - Federated final accuracy: {fed_history['accuracy'][-1]:.2f}%\")\n",
    "print(f\"  - Centralized final accuracy: {central_history['accuracy'][-1]:.2f}%\")\n",
    "print(f\"  - Accuracy gap: {abs(fed_history['accuracy'][-1] - central_history['accuracy'][-1]):.2f}%\")\n",
    "print(f\"\\n  Federated learning achieves comparable performance while preserving data privacy!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hands-On Activity: Exploring Non-IID Data\n",
    "\n",
    "**Challenge**: Investigate how non-IID (non-identically distributed) data affects federated learning performance.\n",
    "\n",
    "In real-world scenarios, client data is often non-IID—each client may have different data distributions. For example:\n",
    "- Mobile keyboard users type different types of text\n",
    "- Hospital patients have varying demographics\n",
    "- Smart home devices have different usage patterns\n",
    "\n",
    "### Task: Compare IID vs. Non-IID Performance\n",
    "\n",
    "Modify the code below to train with non-IID data distribution (each client gets only 2 digit classes)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create non-IID client datasets\n",
    "client_datasets_noniid = create_client_datasets(train_dataset, NUM_CLIENTS, iid=False)\n",
    "\n",
    "print(f\"Created {NUM_CLIENTS} client datasets (Non-IID):\")\n",
    "for i, dataset in enumerate(client_datasets_noniid):\n",
    "    print(f\"  Client {i+1}: {len(dataset)} samples\")\n",
    "    # Show label distribution for first few samples\n",
    "    labels = [dataset[j][1] for j in range(min(100, len(dataset)))]\n",
    "    unique_labels = sorted(set(labels))\n",
    "    print(f\"    Sample labels: {unique_labels}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modified federated learning function for non-IID experiment\n",
    "def federated_learning_noniid(client_datasets, num_rounds=10, local_epochs=1):\n",
    "    \"\"\"Federated learning with specified client datasets\"\"\"\n",
    "    global_model = SimpleCNN().to(device)\n",
    "    history = {'accuracy': [], 'loss': []}\n",
    "    \n",
    "    for round_num in range(num_rounds):\n",
    "        print(f\"Round {round_num + 1}/{num_rounds}\", end=' ')\n",
    "        \n",
    "        client_models = []\n",
    "        client_weights = []\n",
    "        \n",
    "        for client_id in range(NUM_CLIENTS):\n",
    "            client_model = SimpleCNN().to(device)\n",
    "            client_model.load_state_dict(global_model.state_dict())\n",
    "            \n",
    "            state_dict, num_samples = client_update(\n",
    "                client_model, \n",
    "                client_datasets[client_id],\n",
    "                epochs=local_epochs\n",
    "            )\n",
    "            \n",
    "            client_models.append(state_dict)\n",
    "            client_weights.append(num_samples)\n",
    "        \n",
    "        global_model = federated_averaging(global_model, client_models, client_weights)\n",
    "        accuracy, loss = evaluate(global_model, test_loader)\n",
    "        history['accuracy'].append(accuracy)\n",
    "        history['loss'].append(loss)\n",
    "        \n",
    "        print(f\"- Accuracy: {accuracy:.2f}%, Loss: {loss:.4f}\")\n",
    "    \n",
    "    return global_model, history\n",
    "\n",
    "print(\"\\nTraining with Non-IID data...\\n\")\n",
    "fed_model_noniid, fed_history_noniid = federated_learning_noniid(\n",
    "    client_datasets_noniid,\n",
    "    num_rounds=NUM_ROUNDS,\n",
    "    local_epochs=LOCAL_EPOCHS\n",
    ")\n",
    "\n",
    "print(f\"\\nNon-IID Federated Learning Complete!\")\n",
    "print(f\"Final Test Accuracy: {fed_history_noniid['accuracy'][-1]:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare IID vs. Non-IID Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Plot accuracy comparison\n",
    "ax1.plot(range(1, NUM_ROUNDS + 1), fed_history['accuracy'], \n",
    "         marker='o', label='IID Data', linewidth=2, color='blue')\n",
    "ax1.plot(range(1, NUM_ROUNDS + 1), fed_history_noniid['accuracy'], \n",
    "         marker='^', label='Non-IID Data', linewidth=2, color='red')\n",
    "ax1.plot(range(1, NUM_ROUNDS + 1), central_history['accuracy'], \n",
    "         marker='s', label='Centralized (baseline)', linewidth=2, \n",
    "         color='green', linestyle='--', alpha=0.7)\n",
    "ax1.set_xlabel('Communication Round', fontsize=12)\n",
    "ax1.set_ylabel('Test Accuracy (%)', fontsize=12)\n",
    "ax1.set_title('IID vs Non-IID Performance', fontsize=14, fontweight='bold')\n",
    "ax1.legend(fontsize=10)\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Plot loss comparison\n",
    "ax2.plot(range(1, NUM_ROUNDS + 1), fed_history['loss'], \n",
    "         marker='o', label='IID Data', linewidth=2, color='blue')\n",
    "ax2.plot(range(1, NUM_ROUNDS + 1), fed_history_noniid['loss'], \n",
    "         marker='^', label='Non-IID Data', linewidth=2, color='red')\n",
    "ax2.plot(range(1, NUM_ROUNDS + 1), central_history['loss'], \n",
    "         marker='s', label='Centralized (baseline)', linewidth=2, \n",
    "         color='green', linestyle='--', alpha=0.7)\n",
    "ax2.set_xlabel('Communication Round', fontsize=12)\n",
    "ax2.set_ylabel('Test Loss', fontsize=12)\n",
    "ax2.set_title('Loss Curves', fontsize=14, fontweight='bold')\n",
    "ax2.legend(fontsize=10)\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('iid_vs_noniid_comparison.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"PERFORMANCE SUMMARY\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\\nCentralized Learning:  {central_history['accuracy'][-1]:.2f}%\")\n",
    "print(f\"Federated (IID):       {fed_history['accuracy'][-1]:.2f}%\")\n",
    "print(f\"Federated (Non-IID):   {fed_history_noniid['accuracy'][-1]:.2f}%\")\n",
    "print(f\"\\nPerformance degradation (Non-IID vs IID): \"\n",
    "      f\"{fed_history['accuracy'][-1] - fed_history_noniid['accuracy'][-1]:.2f}%\")\n",
    "print(\"\\nKey Insight: Non-IID data distribution causes slower convergence and \")\n",
    "print(\"lower final accuracy, highlighting a major challenge in federated learning!\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Key Takeaways\n",
    "\n",
    "### What We Learned\n",
    "\n",
    "1. **Federated Learning Workflow**:\n",
    "   - Clients train locally on private data\n",
    "   - Server aggregates model updates using FedAvg\n",
    "   - Privacy is preserved as raw data never leaves devices\n",
    "\n",
    "2. **Performance Characteristics**:\n",
    "   - Federated learning can achieve near-centralized performance with IID data\n",
    "   - Non-IID data significantly degrades convergence and accuracy\n",
    "   - Communication rounds are the bottleneck (not compute time)\n",
    "\n",
    "3. **Practical Challenges**:\n",
    "   - **Statistical Heterogeneity**: Non-IID data is common in real deployments\n",
    "   - **Communication Costs**: Each round requires sending full model parameters\n",
    "   - **System Heterogeneity**: Clients have varying computational capabilities\n",
    "   - **Privacy Leakage**: Model updates can still reveal sensitive information\n",
    "\n",
    "### Advanced Techniques (Beyond This Lesson)\n",
    "\n",
    "1. **Communication Efficiency**:\n",
    "   - Gradient compression and quantization\n",
    "   - Sparse updates (only send changed parameters)\n",
    "   - Model distillation\n",
    "\n",
    "2. **Privacy Enhancement**:\n",
    "   - Differential privacy (adding noise to updates)\n",
    "   - Secure aggregation (encrypted model updates)\n",
    "   - Homomorphic encryption\n",
    "\n",
    "3. **Non-IID Mitigation**:\n",
    "   - Personalized federated learning\n",
    "   - FedProx (proximal term for stability)\n",
    "   - Multi-task learning approaches\n",
    "\n",
    "4. **Scalability**:\n",
    "   - Hierarchical federated learning\n",
    "   - Asynchronous updates\n",
    "   - Client selection strategies\n",
    "\n",
    "### When to Use Federated Learning\n",
    "\n",
    "✅ **Good Use Cases**:\n",
    "- Sensitive data (healthcare, finance)\n",
    "- Regulatory constraints (GDPR compliance)\n",
    "- Data cannot be centralized (edge devices, mobile)\n",
    "- Large-scale distributed data sources\n",
    "\n",
    "❌ **Poor Use Cases**:\n",
    "- Data can be easily centralized\n",
    "- No privacy concerns\n",
    "- Extremely heterogeneous data distributions\n",
    "- High communication costs unacceptable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resources and Further Learning\n",
    "\n",
    "### Foundational Papers\n",
    "\n",
    "1. **McMahan et al. (2017)** - \"Communication-Efficient Learning of Deep Networks from Decentralized Data\"\n",
    "   - Original FedAvg paper\n",
    "   - [arXiv:1602.05629](https://arxiv.org/abs/1602.05629)\n",
    "\n",
    "2. **Li et al. (2020)** - \"Federated Optimization in Heterogeneous Networks\"\n",
    "   - Introduces FedProx for non-IID data\n",
    "   - [arXiv:1812.06127](https://arxiv.org/abs/1812.06127)\n",
    "\n",
    "3. **Kairouz et al. (2021)** - \"Advances and Open Problems in Federated Learning\"\n",
    "   - Comprehensive survey of the field\n",
    "   - [arXiv:1912.04977](https://arxiv.org/abs/1912.04977)\n",
    "\n",
    "### Frameworks and Tools\n",
    "\n",
    "1. **TensorFlow Federated**: https://www.tensorflow.org/federated\n",
    "2. **PySyft**: https://github.com/OpenMined/PySyft\n",
    "3. **Flower (flwr)**: https://flower.dev/\n",
    "4. **FedML**: https://fedml.ai/\n",
    "\n",
    "### Additional Topics to Explore\n",
    "\n",
    "- Differential privacy in federated learning\n",
    "- Secure aggregation protocols\n",
    "- Federated learning on edge devices\n",
    "- Cross-silo vs. cross-device federated learning\n",
    "- Personalized federated learning\n",
    "- Vertical federated learning\n",
    "\n",
    "### Datasets for Experimentation\n",
    "\n",
    "- LEAF Benchmark: https://leaf.cmu.edu/\n",
    "- FEMNIST (Federated EMNIST)\n",
    "- Shakespeare text dataset\n",
    "- Reddit and StackOverflow datasets\n",
    "\n",
    "---\n",
    "\n",
    "## Next Steps\n",
    "\n",
    "1. **Experiment**: Modify hyperparameters (local epochs, learning rate, client selection)\n",
    "2. **Explore**: Try different datasets and model architectures\n",
    "3. **Extend**: Implement differential privacy or secure aggregation\n",
    "4. **Read**: Study the foundational papers listed above\n",
    "5. **Build**: Create a federated learning application for a real-world use case\n",
    "\n",
    "**Continue to Lesson 92**: Communication-Efficient Learning techniques!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
