{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# Day 37: Transfer Learning: Fine-tuning Pre-trained Models\n\n## Introduction\n\nWelcome to Day 37! Today we'll explore one of the most powerful techniques in modern deep learning: **Transfer Learning** and **Fine-tuning Pre-trained Models**.\n\nImagine you're learning to play the guitar. Would you start by mastering music theory from scratch, or would you leverage your existing knowledge of rhythm, melody, and hand-eye coordination? Transfer learning follows the same principle: instead of training neural networks from scratch, we leverage models that have already learned useful features from massive datasets.\n\nIn the real world, most organizations don't have millions of labeled images or the computational resources to train models like ResNet, BERT, or GPT from scratch. Transfer learning democratizes deep learning by allowing us to:\n- **Reduce training time** from weeks to hours or minutes\n- **Achieve better performance** with limited data (often just hundreds of examples)\n- **Lower computational costs** by reusing pre-trained weights\n- **Accelerate experimentation** and prototyping\n\n### Why This Matters\n\nTransfer learning has enabled breakthroughs across domains:\n- **Computer Vision**: Medical imaging diagnosis with limited labeled scans\n- **Natural Language Processing**: Domain-specific chatbots built on GPT or BERT\n- **Speech Recognition**: Custom voice assistants with minimal training data\n- **Recommendation Systems**: Cold-start problems solved using pre-trained embeddings\n\n### Learning Objectives\n\nBy the end of this lesson, you will be able to:\n\n1. **Understand** the fundamental concepts of transfer learning and when to apply it\n2. **Distinguish** between feature extraction and fine-tuning approaches\n3. **Implement** transfer learning using pre-trained models (ResNet, VGG, MobileNet)\n4. **Apply** fine-tuning strategies including layer freezing and discriminative learning rates\n5. **Avoid** common pitfalls like catastrophic forgetting and overfitting\n6. **Build** a practical image classifier using transfer learning on a custom dataset",
   "id": "cell-introduction"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Theory\n\n### What is Transfer Learning?\n\n**Transfer Learning** is a machine learning technique where a model trained on one task is repurposed for a related task. Instead of learning from scratch, the model transfers knowledge from a source domain to a target domain.\n\n**Mathematical Formulation:**\n\nGiven:\n- Source domain $\\mathcal{D}_S$ with task $\\mathcal{T}_S$\n- Target domain $\\mathcal{D}_T$ with task $\\mathcal{T}_T$\n\nTransfer learning aims to improve the learning of the target predictive function $f_T$ in $\\mathcal{D}_T$ using knowledge from $\\mathcal{D}_S$ and $\\mathcal{T}_S$, where $\\mathcal{D}_S \\neq \\mathcal{D}_T$ or $\\mathcal{T}_S \\neq \\mathcal{T}_T$.\n\n### Why Does Transfer Learning Work?\n\n**Feature Hierarchy in Deep Networks:**\n\nDeep neural networks learn hierarchical representations:\n- **Early layers**: Learn generic, low-level features (edges, textures, basic shapes)\n- **Middle layers**: Learn mid-level features (object parts, patterns)\n- **Final layers**: Learn task-specific, high-level features (object classes, semantic concepts)\n\nThe key insight: **Early layer features are often transferable across tasks and domains**.\n\n### Transfer Learning Approaches\n\n#### 1. Feature Extraction (Frozen Base)\n\nUse the pre-trained model as a fixed feature extractor:\n\n$$\n\\text{Features} = f_{\\text{pretrained}}(\\mathbf{x}; \\theta_{\\text{frozen}})\n$$\n$$\n\\text{Output} = g(\\text{Features}; \\theta_{\\text{new}})\n$$\n\nWhere:\n- $\\theta_{\\text{frozen}}$ are frozen pre-trained weights\n- $\\theta_{\\text{new}}$ are trainable weights in the new classifier head\n- Only $\\theta_{\\text{new}}$ are updated during training\n\n**Advantages:**\n- Fast training (fewer parameters to update)\n- Requires less data\n- Prevents overfitting on small datasets\n\n**When to use:**\n- Small target dataset (<1000 samples)\n- Target domain similar to source domain\n- Limited computational resources\n\n#### 2. Fine-tuning (Selective Unfreezing)\n\nUnfreeze some or all layers and continue training with a low learning rate:\n\n$$\n\\theta_{\\text{fine-tuned}} = \\theta_{\\text{pretrained}} - \\alpha \\nabla_\\theta \\mathcal{L}(\\theta; \\mathcal{D}_T)\n$$\n\nWhere:\n- $\\alpha$ is a small learning rate (typically $10^{-4}$ to $10^{-5}$)\n- $\\mathcal{L}$ is the loss function on target data $\\mathcal{D}_T$\n- All or selected layers are updated\n\n**Discriminative Learning Rates:**\n\nUse different learning rates for different layers:\n\n$$\n\\theta_l^{(t+1)} = \\theta_l^{(t)} - \\alpha_l \\nabla_{\\theta_l} \\mathcal{L}\n$$\n\nWhere $\\alpha_1 > \\alpha_2 > ... > \\alpha_L$ (higher LR for later layers).\n\n**Advantages:**\n- Better performance on target task\n- Adapts features to target domain\n- Can handle domain shift\n\n**When to use:**\n- Medium to large target dataset (>1000 samples)\n- Target domain differs from source domain\n- Need maximum performance\n\n### Common Pre-trained Models\n\n| Model | Parameters | ImageNet Top-1 | Use Case |\n|-------|-----------|----------------|-----------|\n| **ResNet50** | 25.6M | 76.1% | General-purpose, good balance |\n| **VGG16** | 138M | 71.3% | Simple architecture, feature visualization |\n| **MobileNetV2** | 3.5M | 71.8% | Mobile/embedded devices |\n| **EfficientNetB0** | 5.3M | 77.1% | Best accuracy/size trade-off |\n| **InceptionV3** | 23.8M | 77.9% | Multi-scale feature learning |\n\n### Key Concepts\n\n**1. Catastrophic Forgetting:**\n\nWhen fine-tuning too aggressively, the model \"forgets\" pre-trained knowledge:\n\n$$\n\\text{Performance Drop} = \\text{Perf}_{\\text{source}}(\\theta_{\\text{pretrained}}) - \\text{Perf}_{\\text{source}}(\\theta_{\\text{fine-tuned}})\n$$\n\n**Mitigation strategies:**\n- Use low learning rates ($10^{-4}$ to $10^{-5}$)\n- Freeze early layers\n- Progressive unfreezing (unfreeze layers gradually)\n- Regularization techniques (dropout, weight decay)\n\n**2. Domain Shift:**\n\nWhen source and target domains have different distributions:\n\n$$\nP_S(\\mathbf{x}, y) \\neq P_T(\\mathbf{x}, y)\n$$\n\n**Addressing domain shift:**\n- Fine-tune more layers\n- Data augmentation to bridge the gap\n- Domain adaptation techniques\n- Collect more diverse target data\n\n**3. Layer Freezing Strategy:**\n\n$$\n\\theta_{\\text{model}} = \\{\\theta_{\\text{frozen}}, \\theta_{\\text{trainable}}\\}\n$$\n\nCommon strategies:\n- **Strategy 1**: Freeze all but last layer (feature extraction)\n- **Strategy 2**: Freeze early layers, train late layers\n- **Strategy 3**: Train all layers with discriminative LR\n- **Strategy 4**: Progressive unfreezing (start frozen, gradually unfreeze)",
   "id": "cell-theory"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Import necessary libraries\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import classification_report, confusion_matrix, accuracy_score\nimport warnings\nwarnings.filterwarnings('ignore')\n\n# Set random seeds for reproducibility\nnp.random.seed(42)\n\n# Plotting configuration\nplt.style.use('seaborn-v0_8-darkgrid')\nsns.set_palette(\"husl\")\n\nprint(\"All libraries imported successfully!\")\nprint(f\"NumPy version: {np.__version__}\")\nprint(f\"Pandas version: {pd.__version__}\")",
   "id": "cell-imports"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Visualization: Transfer Learning Concept\n# Create a visual representation of transfer learning workflow\n\nfig, axes = plt.subplots(1, 3, figsize=(16, 5))\n\n# Subplot 1: Training from Scratch\nax1 = axes[0]\nlayers = ['Input', 'Conv1', 'Conv2', 'Conv3', 'Conv4', 'FC']\ncolors_scratch = ['#FF6B6B', '#FF6B6B', '#FF6B6B', '#FF6B6B', '#FF6B6B', '#FF6B6B']\ny_pos = np.arange(len(layers))\nax1.barh(y_pos, [1]*len(layers), color=colors_scratch, alpha=0.7, edgecolor='black', linewidth=2)\nax1.set_yticks(y_pos)\nax1.set_yticklabels(layers)\nax1.set_xlabel('Training Required', fontsize=12)\nax1.set_title('Training from Scratch\\n(All layers randomly initialized)', fontsize=13, fontweight='bold')\nax1.set_xlim(0, 1.2)\nax1.legend(['All layers trainable'], loc='upper right')\n\n# Subplot 2: Feature Extraction\nax2 = axes[1]\ncolors_frozen = ['#4ECDC4', '#4ECDC4', '#4ECDC4', '#4ECDC4', '#4ECDC4', '#FF6B6B']\nbars = ax2.barh(y_pos, [1]*len(layers), color=colors_frozen, alpha=0.7, edgecolor='black', linewidth=2)\nax2.set_yticks(y_pos)\nax2.set_yticklabels(layers)\nax2.set_xlabel('Training Required', fontsize=12)\nax2.set_title('Feature Extraction\\n(Only classifier trained)', fontsize=13, fontweight='bold')\nax2.set_xlim(0, 1.2)\nax2.legend(['Frozen (pre-trained)', 'Trainable'], loc='upper right')\n\n# Subplot 3: Fine-tuning\nax3 = axes[2]\ncolors_finetune = ['#4ECDC4', '#4ECDC4', '#95E1D3', '#95E1D3', '#FFE66D', '#FF6B6B']\nax3.barh(y_pos, [1]*len(layers), color=colors_finetune, alpha=0.7, edgecolor='black', linewidth=2)\nax3.set_yticks(y_pos)\nax3.set_yticklabels(layers)\nax3.set_xlabel('Training Required', fontsize=12)\nax3.set_title('Fine-tuning\\n(Gradual unfreezing)', fontsize=13, fontweight='bold')\nax3.set_xlim(0, 1.2)\nax3.legend(['Frozen', 'Low LR', 'Medium LR', 'High LR'], loc='upper right')\n\nplt.tight_layout()\nplt.savefig('transfer_learning_comparison.png', dpi=150, bbox_inches='tight')\nplt.show()\n\nprint(\"‚úì Transfer learning strategies visualized!\")\nprint(\"\\nKey Insight:\")\nprint(\"- Frozen layers (cyan): Use pre-trained weights without modification\")\nprint(\"- Trainable layers (red/yellow): Adapted to target task\")\nprint(\"- Fine-tuning uses discriminative learning rates for different layers\")",
   "id": "cell-visualization"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "## Practical Implementation Example\n\n# Since we're demonstrating concepts, let's simulate transfer learning workflow\n# In real scenarios, you would use PyTorch or TensorFlow with actual pre-trained models\n\nprint(\"=\" * 70)\nprint(\"TRANSFER LEARNING SIMULATION\")\nprint(\"=\" * 70)\n\n# Step 1: Simulate a pre-trained model (source domain: ImageNet-like)\nprint(\"\\n1. LOADING PRE-TRAINED MODEL\")\nprint(\"-\" * 70)\n\nclass PretrainedModel:\n    \"\"\"Simulates a pre-trained CNN model\"\"\"\n    def __init__(self, name=\"ResNet50\"):\n        self.name = name\n        self.layers = {\n            'conv1': {'params': 9408, 'frozen': False},\n            'conv2_x': {'params': 215808, 'frozen': False},\n            'conv3_x': {'params': 1219584, 'frozen': False},\n            'conv4_x': {'params': 7098368, 'frozen': False},\n            'conv5_x': {'params': 14964736, 'frozen': False},\n            'fc': {'params': 2048000, 'frozen': False}  # Original: 1000 classes\n        }\n        self.total_params = sum(l['params'] for l in self.layers.values())\n        self.imagenet_accuracy = 0.761\n        \n    def freeze_layers(self, layers_to_freeze):\n        \"\"\"Freeze specified layers\"\"\"\n        for layer in layers_to_freeze:\n            if layer in self.layers:\n                self.layers[layer]['frozen'] = True\n                \n    def unfreeze_layers(self, layers_to_unfreeze):\n        \"\"\"Unfreeze specified layers\"\"\"\n        for layer in layers_to_unfreeze:\n            if layer in self.layers:\n                self.layers[layer]['frozen'] = False\n                \n    def get_trainable_params(self):\n        \"\"\"Count trainable parameters\"\"\"\n        return sum(l['params'] for l in self.layers.values() if not l['frozen'])\n    \n    def summary(self):\n        \"\"\"Print model summary\"\"\"\n        print(f\"\\nModel: {self.name}\")\n        print(f\"Total Parameters: {self.total_params:,}\")\n        print(f\"ImageNet Top-1 Accuracy: {self.imagenet_accuracy*100:.1f}%\")\n        print(\"\\nLayer Configuration:\")\n        for layer, info in self.layers.items():\n            status = \"FROZEN ‚ùÑÔ∏è\" if info['frozen'] else \"TRAINABLE üî•\"\n            print(f\"  {layer:12s}: {info['params']:>10,} params - {status}\")\n        trainable = self.get_trainable_params()\n        print(f\"\\nTrainable Parameters: {trainable:,} ({trainable/self.total_params*100:.1f}%)\")\n\n# Load pre-trained model\nmodel = PretrainedModel(\"ResNet50\")\nmodel.summary()\n\n# Step 2: Scenario - Fine-tune for medical imaging (only 500 samples)\nprint(\"\\n\\n2. TARGET TASK: Medical Image Classification\")\nprint(\"-\" * 70)\nprint(\"Task: Classify chest X-rays into 5 disease categories\")\nprint(\"Dataset: 500 labeled images (100 per class)\")\nprint(\"Challenge: Limited data, domain shift from natural images to X-rays\")\n\n# Step 3: Strategy 1 - Feature Extraction\nprint(\"\\n\\n3. STRATEGY 1: Feature Extraction (Frozen Base)\")\nprint(\"-\" * 70)\nmodel_fe = PretrainedModel(\"ResNet50-FeatureExtractor\")\n# Freeze all convolutional layers\nmodel_fe.freeze_layers(['conv1', 'conv2_x', 'conv3_x', 'conv4_x', 'conv5_x'])\nmodel_fe.summary()\n\nprint(\"\\n‚úì Benefits:\")\nprint(\"  - Fast training (only 2M parameters to train)\")\nprint(\"  - Prevents overfitting on small dataset\")\nprint(\"  - Uses pre-trained features as-is\")\nprint(\"  - Training time: ~5-10 minutes\")\n\n# Step 4: Strategy 2 - Fine-tuning\nprint(\"\\n\\n4. STRATEGY 2: Fine-tuning (Partial Unfreezing)\")\nprint(\"-\" * 70)\nmodel_ft = PretrainedModel(\"ResNet50-FineTuned\")\n# Freeze only early layers\nmodel_ft.freeze_layers(['conv1', 'conv2_x'])\nmodel_ft.summary()\n\nprint(\"\\n‚úì Benefits:\")\nprint(\"  - Adapts features to medical imaging domain\")\nprint(\"  - Balances pre-trained knowledge with task-specific learning\")\nprint(\"  - Better performance than feature extraction\")\nprint(\"  - Training time: ~30-60 minutes\")\n\n# Step 5: Compare approaches\nprint(\"\\n\\n5. PERFORMANCE COMPARISON\")\nprint(\"-\" * 70)\n\ncomparison_data = {\n    'Approach': ['Training from Scratch', 'Feature Extraction', 'Fine-tuning (Partial)', 'Fine-tuning (Full)'],\n    'Trainable Params': ['25.6M', '2.0M', '23.3M', '25.6M'],\n    'Training Time': ['6 hours', '10 min', '45 min', '2 hours'],\n    'Validation Accuracy': ['45%', '78%', '89%', '92%'],\n    'Overfitting Risk': ['Very High', 'Low', 'Medium', 'High']\n}\n\ncomparison_df = pd.DataFrame(comparison_data)\nprint(\"\\n\" + comparison_df.to_string(index=False))\n\nprint(\"\\n\\n‚úì Key Takeaway:\")\nprint(\"  With only 500 samples, transfer learning (feature extraction & fine-tuning)\")\nprint(\"  dramatically outperforms training from scratch!\")\n\n# Step 6: Visualize parameter efficiency\nfig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))\n\n# Plot 1: Parameter efficiency\napproaches = ['From\\nScratch', 'Feature\\nExtraction', 'Fine-tuning\\n(Partial)', 'Fine-tuning\\n(Full)']\ntrainable_params = [25.6, 2.0, 23.3, 25.6]\ncolors = ['#FF6B6B', '#4ECDC4', '#95E1D3', '#FFE66D']\n\nbars = ax1.bar(approaches, trainable_params, color=colors, alpha=0.7, edgecolor='black', linewidth=2)\nax1.set_ylabel('Trainable Parameters (Millions)', fontsize=11)\nax1.set_title('Parameter Efficiency Comparison', fontsize=13, fontweight='bold')\nax1.set_ylim(0, 30)\n\n# Add value labels on bars\nfor bar, val in zip(bars, trainable_params):\n    height = bar.get_height()\n    ax1.text(bar.get_x() + bar.get_width()/2., height,\n             f'{val}M', ha='center', va='bottom', fontsize=10, fontweight='bold')\n\n# Plot 2: Performance vs Training Time\naccuracies = [45, 78, 89, 92]\ntimes = [360, 10, 45, 120]  # minutes\n\nax2.scatter(times, accuracies, s=[p*20 for p in trainable_params], \n           c=colors, alpha=0.6, edgecolors='black', linewidth=2)\nax2.set_xlabel('Training Time (minutes)', fontsize=11)\nax2.set_ylabel('Validation Accuracy (%)', fontsize=11)\nax2.set_title('Performance vs Training Time Trade-off', fontsize=13, fontweight='bold')\nax2.grid(True, alpha=0.3)\n\n# Add labels\nfor i, approach in enumerate(['Scratch', 'Feature Ext.', 'Fine-tune (P)', 'Fine-tune (F)']):\n    ax2.annotate(approach, (times[i], accuracies[i]), \n                xytext=(10, 10), textcoords='offset points',\n                fontsize=9, bbox=dict(boxstyle='round,pad=0.3', facecolor=colors[i], alpha=0.3))\n\nplt.tight_layout()\nplt.savefig('transfer_learning_efficiency.png', dpi=150, bbox_inches='tight')\nplt.show()\n\nprint(\"\\n‚úì Visualization complete!\")",
   "id": "cell-examples"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Hands-On Activity: Transfer Learning Decision Framework\n\nIn this activity, you'll build a **decision framework** to determine the best transfer learning strategy based on dataset characteristics and computational constraints.\n\n### Scenario\n\nYou're a machine learning engineer consulting for different companies, each with unique requirements. For each scenario, you'll:\n\n1. Analyze the dataset characteristics\n2. Consider computational constraints\n3. Recommend the optimal transfer learning strategy\n4. Justify your decision\n\n### Decision Factors\n\nKey factors to consider:\n- **Dataset size**: Small (<1K), Medium (1K-10K), Large (>10K)\n- **Domain similarity**: How similar is the target domain to ImageNet?\n- **Computational budget**: Time and GPU resources available\n- **Performance requirements**: Is maximum accuracy critical?\n\nLet's work through real-world scenarios!",
   "id": "cell-activity"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Hands-On Activity Implementation\n\nclass TransferLearningAdvisor:\n    \"\"\"Decision support system for transfer learning strategy selection\"\"\"\n    \n    def __init__(self):\n        self.strategies = {\n            'feature_extraction': {\n                'name': 'Feature Extraction (Frozen Base)',\n                'frozen_layers': ['all_conv'],\n                'trainable_layers': ['fc'],\n                'learning_rate': 1e-3,\n                'epochs': 10-20,\n                'best_for': 'Small datasets, similar domains'\n            },\n            'fine_tuning_conservative': {\n                'name': 'Conservative Fine-tuning',\n                'frozen_layers': ['conv1', 'conv2'],\n                'trainable_layers': ['conv3', 'conv4', 'conv5', 'fc'],\n                'learning_rate': 1e-4,\n                'epochs': 20-30,\n                'best_for': 'Medium datasets, moderate domain shift'\n            },\n            'fine_tuning_aggressive': {\n                'name': 'Aggressive Fine-tuning',\n                'frozen_layers': [],\n                'trainable_layers': ['all'],\n                'learning_rate': 1e-5,\n                'epochs': 30-50,\n                'best_for': 'Large datasets, significant domain shift'\n            },\n            'from_scratch': {\n                'name': 'Train from Scratch',\n                'frozen_layers': [],\n                'trainable_layers': ['all'],\n                'learning_rate': 1e-3,\n                'epochs': 100-200,\n                'best_for': 'Very large datasets, completely different domain'\n            }\n        }\n    \n    def analyze_scenario(self, dataset_size, domain_similarity, compute_budget, priority):\n        \"\"\"\n        Recommend transfer learning strategy based on scenario\n        \n        Parameters:\n        - dataset_size: 'small' (<1000), 'medium' (1K-10K), 'large' (>10K)\n        - domain_similarity: 'high' (similar to ImageNet), 'medium', 'low'\n        - compute_budget: 'limited' (<1 hour), 'moderate' (1-6 hours), 'high' (>6 hours)\n        - priority: 'speed' or 'accuracy'\n        \"\"\"\n        print(\"=\" * 70)\n        print(\"TRANSFER LEARNING STRATEGY RECOMMENDATION\")\n        print(\"=\" * 70)\n        \n        print(f\"\\nüìä Scenario Analysis:\")\n        print(f\"  Dataset Size: {dataset_size.upper()}\")\n        print(f\"  Domain Similarity to ImageNet: {domain_similarity.upper()}\")\n        print(f\"  Compute Budget: {compute_budget.upper()}\")\n        print(f\"  Priority: {priority.upper()}\")\n        \n        # Decision logic\n        if dataset_size == 'small':\n            if domain_similarity in ['high', 'medium']:\n                recommended = 'feature_extraction'\n            else:\n                recommended = 'fine_tuning_conservative'\n        elif dataset_size == 'medium':\n            if compute_budget == 'limited' or priority == 'speed':\n                recommended = 'feature_extraction'\n            else:\n                recommended = 'fine_tuning_conservative'\n        else:  # large dataset\n            if domain_similarity == 'low' and compute_budget == 'high':\n                recommended = 'from_scratch'\n            else:\n                recommended = 'fine_tuning_aggressive'\n        \n        strategy = self.strategies[recommended]\n        \n        print(f\"\\n‚úÖ RECOMMENDED STRATEGY: {strategy['name']}\")\n        print(f\"\\nüìã Implementation Details:\")\n        print(f\"  Frozen Layers: {', '.join(strategy['frozen_layers'])}\")\n        print(f\"  Trainable Layers: {', '.join(strategy['trainable_layers'])}\")\n        print(f\"  Learning Rate: {strategy['learning_rate']}\")\n        print(f\"  Recommended Epochs: {strategy['epochs']}\")\n        print(f\"\\nüí° Best For: {strategy['best_for']}\")\n        \n        return recommended\n\n# Create advisor\nadvisor = TransferLearningAdvisor()\n\nprint(\"\\n\" + \"=\"*70)\nprint(\"SCENARIO 1: Medical Imaging Startup\")\nprint(\"=\"*70)\nprint(\"Context: Classify skin lesions (dermatology)\")\nprint(\"Data: 800 labeled dermoscopy images\")\nprint(\"Goal: Build MVP in 2 days\")\nprint()\n\nadvisor.analyze_scenario(\n    dataset_size='small',\n    domain_similarity='medium',\n    compute_budget='limited',\n    priority='speed'\n)\n\nprint(\"\\n\\n\" + \"=\"*70)\nprint(\"SCENARIO 2: E-commerce Product Categorization\")\nprint(\"=\"*70)\nprint(\"Context: Categorize fashion items (200 categories)\")\nprint(\"Data: 50,000 product images\")\nprint(\"Goal: Maximize accuracy for search rankings\")\nprint()\n\nadvisor.analyze_scenario(\n    dataset_size='large',\n    domain_similarity='high',\n    compute_budget='moderate',\n    priority='accuracy'\n)\n\nprint(\"\\n\\n\" + \"=\"*70)\nprint(\"SCENARIO 3: Satellite Imagery Analysis\")\nprint(\"=\"*70)\nprint(\"Context: Detect deforestation from satellite images\")\nprint(\"Data: 5,000 labeled satellite patches\")\nprint(\"Goal: Deploy model for environmental monitoring\")\nprint()\n\nadvisor.analyze_scenario(\n    dataset_size='medium',\n    domain_similarity='low',\n    compute_budget='moderate',\n    priority='accuracy'\n)\n\n# Visualize decision tree\nprint(\"\\n\\n\" + \"=\"*70)\nprint(\"DECISION FLOWCHART\")\nprint(\"=\"*70)\n\nfig, ax = plt.subplots(figsize=(14, 10))\nax.axis('off')\n\n# Title\nax.text(0.5, 0.95, 'Transfer Learning Strategy Decision Tree', \n        ha='center', va='top', fontsize=16, fontweight='bold',\n        bbox=dict(boxstyle='round,pad=0.5', facecolor='lightblue', alpha=0.7))\n\n# Level 1: Dataset Size\nax.text(0.5, 0.85, 'Dataset Size?', ha='center', va='center', fontsize=12,\n        bbox=dict(boxstyle='round,pad=0.4', facecolor='#FFE66D', alpha=0.7))\n\n# Level 2: Small branch\nax.text(0.2, 0.70, 'Small\\n(<1K)', ha='center', va='center', fontsize=10,\n        bbox=dict(boxstyle='round,pad=0.3', facecolor='#FF6B6B', alpha=0.5))\nax.arrow(0.45, 0.83, -0.23, -0.10, head_width=0.02, head_length=0.02, fc='black', ec='black')\n\nax.text(0.2, 0.55, 'Domain\\nSimilarity?', ha='center', va='center', fontsize=9,\n        bbox=dict(boxstyle='round,pad=0.3', facecolor='#95E1D3', alpha=0.5))\nax.arrow(0.2, 0.67, 0, -0.09, head_width=0.02, head_length=0.02, fc='black', ec='black')\n\nax.text(0.1, 0.40, '‚úÖ Feature\\nExtraction', ha='center', va='center', fontsize=8,\n        bbox=dict(boxstyle='round,pad=0.3', facecolor='#4ECDC4', alpha=0.7))\nax.text(0.08, 0.36, 'High/Med', ha='center', fontsize=7, style='italic')\n\nax.text(0.3, 0.40, '‚úÖ Conservative\\nFine-tuning', ha='center', va='center', fontsize=8,\n        bbox=dict(boxstyle='round,pad=0.3', facecolor='#4ECDC4', alpha=0.7))\nax.text(0.28, 0.36, 'Low', ha='center', fontsize=7, style='italic')\n\n# Level 2: Medium branch\nax.text(0.5, 0.70, 'Medium\\n(1K-10K)', ha='center', va='center', fontsize=10,\n        bbox=dict(boxstyle='round,pad=0.3', facecolor='#FFE66D', alpha=0.5))\nax.arrow(0.5, 0.83, 0, -0.10, head_width=0.02, head_length=0.02, fc='black', ec='black')\n\nax.text(0.5, 0.55, 'Priority?', ha='center', va='center', fontsize=9,\n        bbox=dict(boxstyle='round,pad=0.3', facecolor='#95E1D3', alpha=0.5))\nax.arrow(0.5, 0.67, 0, -0.09, head_width=0.02, head_length=0.02, fc='black', ec='black')\n\nax.text(0.43, 0.40, '‚úÖ Feature\\nExtraction', ha='center', va='center', fontsize=8,\n        bbox=dict(boxstyle='round,pad=0.3', facecolor='#4ECDC4', alpha=0.7))\nax.text(0.41, 0.36, 'Speed', ha='center', fontsize=7, style='italic')\n\nax.text(0.57, 0.40, '‚úÖ Conservative\\nFine-tuning', ha='center', va='center', fontsize=8,\n        bbox=dict(boxstyle='round,pad=0.3', facecolor='#4ECDC4', alpha=0.7))\nax.text(0.55, 0.36, 'Accuracy', ha='center', fontsize=7, style='italic')\n\n# Level 2: Large branch\nax.text(0.8, 0.70, 'Large\\n(>10K)', ha='center', va='center', fontsize=10,\n        bbox=dict(boxstyle='round,pad=0.3', facecolor='#95E1D3', alpha=0.5))\nax.arrow(0.55, 0.83, 0.23, -0.10, head_width=0.02, head_length=0.02, fc='black', ec='black')\n\nax.text(0.8, 0.55, 'Domain +\\nCompute?', ha='center', va='center', fontsize=9,\n        bbox=dict(boxstyle='round,pad=0.3', facecolor='#95E1D3', alpha=0.5))\nax.arrow(0.8, 0.67, 0, -0.09, head_width=0.02, head_length=0.02, fc='black', ec='black')\n\nax.text(0.7, 0.40, '‚úÖ Aggressive\\nFine-tuning', ha='center', va='center', fontsize=8,\n        bbox=dict(boxstyle='round,pad=0.3', facecolor='#4ECDC4', alpha=0.7))\nax.text(0.68, 0.36, 'Med similarity', ha='center', fontsize=7, style='italic')\n\nax.text(0.9, 0.40, '‚úÖ Train from\\nScratch', ha='center', va='center', fontsize=8,\n        bbox=dict(boxstyle='round,pad=0.3', facecolor='#4ECDC4', alpha=0.7))\nax.text(0.88, 0.36, 'Low sim + High compute', ha='center', fontsize=7, style='italic')\n\n# Legend\nax.text(0.5, 0.25, 'üìå Key Guidelines:', ha='center', fontsize=11, fontweight='bold')\nax.text(0.5, 0.20, '‚Ä¢ Small data (<1K): Always use transfer learning', ha='center', fontsize=9)\nax.text(0.5, 0.17, '‚Ä¢ Medium data (1K-10K): Transfer learning highly recommended', ha='center', fontsize=9)\nax.text(0.5, 0.14, '‚Ä¢ Large data (>10K): Consider training from scratch if domain is very different', ha='center', fontsize=9)\nax.text(0.5, 0.11, '‚Ä¢ Similar domains: Start with feature extraction', ha='center', fontsize=9)\nax.text(0.5, 0.08, '‚Ä¢ Different domains: Use fine-tuning with careful learning rates', ha='center', fontsize=9)\n\nplt.tight_layout()\nplt.savefig('transfer_learning_decision_tree.png', dpi=150, bbox_inches='tight')\nplt.show()\n\nprint(\"\\n‚úì Decision framework visualization complete!\")\nprint(\"\\nüí° Your turn: Think about your own ML project and apply this framework!\")",
   "id": "cell-activity-code"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Key Takeaways\n\nCongratulations on completing Day 37! Here are the essential concepts to remember:\n\n### üéØ Core Concepts\n\n1. **Transfer Learning Enables Learning with Limited Data**\n   - Pre-trained models have already learned useful features from millions of images\n   - You can achieve 90%+ accuracy with just hundreds of labeled examples\n   - Training from scratch requires 10-100x more data to reach similar performance\n\n2. **Two Main Approaches: Feature Extraction vs. Fine-tuning**\n   - **Feature Extraction**: Freeze all convolutional layers, train only classifier (fast, prevents overfitting)\n   - **Fine-tuning**: Unfreeze some/all layers with low learning rates (better performance, requires more data)\n   - Choose based on dataset size, domain similarity, and computational budget\n\n3. **Layer Freezing Strategy is Critical**\n   - Early layers learn generic features (edges, textures) ‚Üí highly transferable\n   - Later layers learn task-specific features ‚Üí often need retraining\n   - Common strategy: Freeze early layers, fine-tune later layers\n\n4. **Use Discriminative Learning Rates**\n   - Different layers should update at different rates\n   - Early layers: Very low LR ($10^{-5}$ to $10^{-6}$) to preserve pre-trained knowledge\n   - Later layers: Higher LR ($10^{-3}$ to $10^{-4}$) to adapt to new task\n   - Prevents catastrophic forgetting while enabling adaptation\n\n5. **Domain Similarity Matters**\n   - Source domain (e.g., ImageNet: natural images) vs. Target domain (e.g., medical images)\n   - **High similarity** ‚Üí Feature extraction often sufficient\n   - **Low similarity** ‚Üí Fine-tuning required, possibly aggressive\n   - Consider data augmentation to bridge domain gaps\n\n### üöÄ Practical Guidelines\n\n| Your Situation | Recommended Strategy | Key Parameters |\n|---------------|---------------------|----------------|\n| <1K samples, similar domain | Feature Extraction | Freeze all conv layers, LR=1e-3 |\n| <1K samples, different domain | Conservative Fine-tuning | Freeze early layers, LR=1e-4 |\n| 1K-10K samples, speed priority | Feature Extraction | Fast training, good baseline |\n| 1K-10K samples, accuracy priority | Conservative Fine-tuning | Unfreeze last 2-3 blocks |\n| >10K samples, similar domain | Aggressive Fine-tuning | Unfreeze all, discriminative LR |\n| >10K samples, very different domain | Consider from scratch | May outperform transfer learning |\n\n### ‚ö†Ô∏è Common Pitfalls to Avoid\n\n1. **Using too high learning rates** ‚Üí Catastrophic forgetting (model loses pre-trained knowledge)\n2. **Not freezing enough layers with small datasets** ‚Üí Overfitting\n3. **Forgetting to replace the final layer** ‚Üí Wrong number of output classes\n4. **Using same LR for all layers** ‚Üí Sub-optimal fine-tuning\n5. **Ignoring data augmentation** ‚Üí Missing opportunity to bridge domain gaps\n\n### üîë Decision Framework Summary\n\n```\nDataset Size:\n  Small (<1K)    ‚Üí Always use transfer learning (feature extraction or conservative fine-tuning)\n  Medium (1-10K) ‚Üí Transfer learning highly recommended\n  Large (>10K)   ‚Üí Transfer learning still beneficial unless domain very different\n\nDomain Similarity:\n  High   ‚Üí Start with feature extraction\n  Medium ‚Üí Conservative fine-tuning\n  Low    ‚Üí Aggressive fine-tuning or collect more data\n\nCompute Budget:\n  Limited   ‚Üí Feature extraction\n  Moderate  ‚Üí Conservative fine-tuning\n  High      ‚Üí Aggressive fine-tuning or from scratch (if data sufficient)\n```\n\n### üí° What You Can Do Now\n\nAfter this lesson, you should be able to:\n- ‚úÖ Select the appropriate transfer learning strategy for your problem\n- ‚úÖ Load and modify pre-trained models (ResNet, VGG, MobileNet, etc.)\n- ‚úÖ Implement layer freezing and discriminative learning rates\n- ‚úÖ Diagnose and fix common transfer learning issues\n- ‚úÖ Make informed trade-offs between speed, accuracy, and data requirements\n\n### üîú Next Steps\n\nTomorrow (Day 38) we'll dive deeper into:\n- **Feature extraction vs. end-to-end learning** trade-offs\n- Advanced fine-tuning techniques (progressive unfreezing, cyclic LR)\n- Multi-task learning and domain adaptation\n- Production deployment considerations",
   "id": "cell-takeaways"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Further Resources\n\n### üìö Essential Reading\n\n1. **[CS231n: Transfer Learning](https://cs231n.github.io/transfer-learning/)**\n   - Stanford's comprehensive guide to transfer learning\n   - Covers when and how to use transfer learning\n   - Includes practical tips and case studies\n\n2. **[PyTorch Transfer Learning Tutorial](https://pytorch.org/tutorials/beginner/transfer_learning_tutorial.html)**\n   - Official PyTorch tutorial with code examples\n   - Demonstrates feature extraction and fine-tuning\n   - Uses real datasets (ants vs. bees classification)\n\n3. **[TensorFlow Transfer Learning Guide](https://www.tensorflow.org/tutorials/images/transfer_learning)**\n   - Official TensorFlow/Keras tutorial\n   - Shows how to use pre-trained models from tf.keras.applications\n   - Covers data augmentation and fine-tuning strategies\n\n4. **[How transferable are features in deep neural networks?](https://arxiv.org/abs/1411.1792)**\n   - Seminal paper by Yosinski et al. (2014)\n   - Empirically analyzes feature transferability across layers\n   - Must-read for understanding why transfer learning works\n\n5. **[A Survey on Transfer Learning](https://ieeexplore.ieee.org/document/5288526)**\n   - Comprehensive academic survey by Pan & Yang (2010)\n   - Covers theory, taxonomy, and applications\n   - Good for deeper theoretical understanding\n\n### üîß Practical Tools & Libraries\n\n6. **[Hugging Face Transformers](https://huggingface.co/docs/transformers/training)**\n   - State-of-the-art pre-trained models for NLP\n   - Easy fine-tuning API for BERT, GPT, T5, etc.\n   - Excellent for text-based transfer learning\n\n7. **[Timm (PyTorch Image Models)](https://github.com/rwightman/pytorch-image-models)**\n   - Collection of 500+ pre-trained vision models\n   - Includes latest architectures (EfficientNet, ViT, ConvNeXt)\n   - High-quality implementations with training scripts\n\n8. **[Fast.ai Practical Deep Learning Course](https://course.fast.ai/)**\n   - Free course with excellent transfer learning coverage\n   - Emphasizes practical techniques and best practices\n   - Includes discriminative learning rates and progressive unfreezing\n\n### üé• Video Tutorials\n\n9. **[Andrew Ng: Transfer Learning (Coursera)](https://www.coursera.org/lecture/convolutional-neural-networks/transfer-learning-4THzO)**\n   - Part of Deep Learning Specialization\n   - Clear explanation of when and why to use transfer learning\n   - Includes practical advice and examples\n\n10. **[Two Minute Papers: Transfer Learning Explained](https://www.youtube.com/watch?v=yofjFQddwHE)**\n    - Quick visual explanation of transfer learning concepts\n    - Shows impressive results and applications\n    - Great for sharing with non-technical stakeholders\n\n### üìä Datasets for Practice\n\n11. **[Kaggle: Dogs vs. Cats](https://www.kaggle.com/c/dogs-vs-cats)**\n    - Classic transfer learning dataset\n    - 25,000 labeled images\n    - Perfect for practicing feature extraction and fine-tuning\n\n12. **[Food-101](https://www.kaggle.com/dansbecker/food-101)**\n    - 101 food categories, 1,000 images per class\n    - Good for testing transfer learning with sufficient data\n    - More challenging than Dogs vs. Cats\n\n13. **[Chest X-Ray Images (Pneumonia)](https://www.kaggle.com/paultimothymooney/chest-xray-pneumonia)**\n    - Medical imaging dataset for pneumonia detection\n    - Demonstrates domain shift (natural images ‚Üí X-rays)\n    - Real-world application of transfer learning\n\n### üõ†Ô∏è Code Repositories\n\n14. **[Papers with Code: Transfer Learning](https://paperswithcode.com/task/transfer-learning)**\n    - Latest research papers with implementations\n    - Benchmark results on standard datasets\n    - Tracks state-of-the-art methods\n\n15. **[Awesome Transfer Learning](https://github.com/artix41/awesome-transfer-learning)**\n    - Curated list of transfer learning resources\n    - Papers, code, tutorials, and applications\n    - Regularly updated with new research\n\n### üèÜ Advanced Topics\n\n16. **[Domain Adaptation: A Survey](https://arxiv.org/abs/1909.00786)**\n    - Covers techniques when source and target domains differ significantly\n    - Includes adversarial domain adaptation, self-training, etc.\n\n17. **[Universal Language Model Fine-tuning (ULMFiT)](https://arxiv.org/abs/1801.06146)**\n    - Transfer learning for NLP\n    - Introduced discriminative fine-tuning and gradual unfreezing\n    - Inspired modern NLP transfer learning (BERT, GPT)\n\n### üíº Industry Applications\n\n18. **[Google AI Blog: Transfer Learning Examples](https://ai.googleblog.com/search/label/transfer%20learning)**\n    - Real-world applications from Google Research\n    - Covers vision, NLP, and speech recognition\n    - Shows how transfer learning is used at scale\n\n19. **[Tesla Autopilot: Transfer Learning](https://www.youtube.com/watch?v=hx7BXih7zx8)**\n    - Andrej Karpathy's talk on using transfer learning for autonomous driving\n    - Discusses challenges and solutions at Tesla\n    - Demonstrates industrial-scale transfer learning\n\n### üìñ Books\n\n20. **[Deep Learning (Goodfellow, Bengio, Courville)](https://www.deeplearningbook.org/)**\n    - Chapter 15.2 covers transfer learning and domain adaptation\n    - Theoretical foundations and mathematical rigor\n    - Free online version available\n\n---\n\n### üéØ Recommended Learning Path\n\n1. **Beginner**: Start with CS231n guide ‚Üí PyTorch/TensorFlow tutorials ‚Üí Practice on Dogs vs. Cats\n2. **Intermediate**: Read Yosinski paper ‚Üí Try Fast.ai course ‚Üí Practice on Food-101 or medical imaging\n3. **Advanced**: Domain adaptation survey ‚Üí Experiment with Timm models ‚Üí Contribute to open-source projects\n\n### üí¨ Community & Support\n\n- **Reddit**: [r/MachineLearning](https://www.reddit.com/r/MachineLearning/) - Discussions and paper announcements\n- **Stack Overflow**: [transfer-learning tag](https://stackoverflow.com/questions/tagged/transfer-learning) - Q&A for implementation issues\n- **Twitter**: Follow [@fchollet](https://twitter.com/fchollet), [@karpathy](https://twitter.com/karpathy), [@jeremyphoward](https://twitter.com/jeremyphoward) for insights\n\n---\n\n**üéâ Congratulations on completing Day 37!** You now have the knowledge and tools to leverage transfer learning in your own projects. Remember: most real-world problems benefit from transfer learning‚Äîyou rarely need to train from scratch!",
   "id": "cell-resources"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}