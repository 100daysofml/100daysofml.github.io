{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# Day 38: Feature Extraction vs End-to-End Learning\n\n## Introduction\n\nWhen working with pre-trained models for transfer learning, one of the most important decisions you'll face is choosing between **feature extraction** and **end-to-end learning**. This choice significantly impacts your model's performance, training time, computational requirements, and ability to generalize to new tasks.\n\n**Feature extraction** treats the pre-trained model as a fixed feature extractor, freezing its weights and only training a new classifier on top. This approach is fast, computationally efficient, and works well when your target task is similar to the original task the model was trained on.\n\n**End-to-end learning** (also called fine-tuning) updates the weights throughout the entire network, allowing the model to adapt its learned features to your specific task. This approach typically achieves better performance but requires more data, computational resources, and careful tuning to avoid overfitting.\n\nUnderstanding when to use each approach—or even combine them—is crucial for building effective deep learning solutions in practice. In this lesson, we'll explore both strategies, compare their trade-offs, and implement them using real examples.\n\n### Learning Objectives\n\nBy the end of this lesson, you will be able to:\n\n- Understand the conceptual differences between feature extraction and end-to-end learning\n- Implement both approaches using PyTorch and TensorFlow/Keras\n- Analyze the computational and performance trade-offs between the two methods\n- Make informed decisions about which approach to use for a given problem\n- Apply progressive unfreezing strategies to combine both approaches",
   "id": "cell-introduction"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Theory\n\n### What is Feature Extraction?\n\nIn **feature extraction**, we use a pre-trained model as a fixed feature extractor. The key idea is to:\n\n1. Load a model pre-trained on a large dataset (e.g., ImageNet, COCO)\n2. **Freeze all weights** in the base model (set `requires_grad=False`)\n3. Remove the original classifier head\n4. Add a new classifier for your specific task\n5. Train **only** the new classifier while keeping the base model fixed\n\nMathematically, if we denote the pre-trained model as $f_{\\theta_{base}}$ and the new classifier as $g_{\\phi}$, we optimize:\n\n$$\n\\min_{\\phi} \\mathcal{L}(g_{\\phi}(f_{\\theta_{base}}(x)), y)\n$$\n\nwhere $\\theta_{base}$ remains fixed and only $\\phi$ is updated during training.\n\n### What is End-to-End Learning (Fine-tuning)?\n\nIn **end-to-end learning**, we update weights throughout the entire network:\n\n1. Load a pre-trained model\n2. **Unfreeze some or all layers** (set `requires_grad=True`)\n3. Replace the final classifier\n4. Train the entire network (or selected layers) with a typically lower learning rate\n\nMathematically, we now optimize:\n\n$$\n\\min_{\\theta_{base}, \\phi} \\mathcal{L}(g_{\\phi}(f_{\\theta_{base}}(x)), y)\n$$\n\nwhere both $\\theta_{base}$ and $\\phi$ are updated.\n\n### Key Differences\n\n| Aspect | Feature Extraction | End-to-End Learning |\n|--------|-------------------|---------------------|\n| **Trainable Parameters** | Only final layers | All or most layers |\n| **Training Time** | Fast (fewer parameters) | Slower (more parameters) |\n| **Data Requirements** | Works with small datasets | Requires more data |\n| **Computational Cost** | Low (no backprop through backbone) | High (full backpropagation) |\n| **Performance** | Good for similar domains | Better for dissimilar domains |\n| **Overfitting Risk** | Lower | Higher (needs regularization) |\n| **Learning Rate** | Standard (e.g., 0.001) | Lower (e.g., 0.0001) |\n\n### When to Use Which Approach?\n\n**Use Feature Extraction when:**\n- You have a **small dataset** (< 10,000 samples)\n- Your task is **similar** to the original task (e.g., ImageNet → other image classification)\n- You have **limited computational resources**\n- You need **fast experimentation and prototyping**\n\n**Use End-to-End Learning when:**\n- You have a **large dataset** (> 10,000 samples)\n- Your task is **different** from the original task (e.g., ImageNet → medical imaging)\n- You need **maximum performance**\n- You have sufficient **computational resources**\n\n**Progressive Unfreezing (Hybrid Approach):**\n\nA common best practice combines both approaches:\n1. Start with feature extraction to quickly train the classifier\n2. Gradually unfreeze layers from top to bottom\n3. Fine-tune with progressively lower learning rates\n\nThis approach often yields the best results while maintaining training stability.\n\n### Mathematical Intuition: Why Does This Work?\n\nDeep neural networks learn **hierarchical features**:\n- **Lower layers**: Generic features (edges, textures, basic shapes)\n- **Middle layers**: Mid-level features (parts, patterns)\n- **Upper layers**: Task-specific features (object-specific patterns)\n\nWhen we freeze lower layers, we preserve these generic features that transfer well across tasks. When we fine-tune upper layers, we adapt the task-specific representations to our new problem.",
   "id": "cell-theory"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Import necessary libraries\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.datasets import load_digits\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.metrics import accuracy_score, classification_report\nimport time\nimport warnings\nwarnings.filterwarnings('ignore')\n\n# Set random seed for reproducibility\nnp.random.seed(42)\n\n# Configure matplotlib\nplt.style.use('seaborn-v0_8-darkgrid')\nsns.set_palette(\"husl\")\n\nprint(\"All libraries imported successfully!\")\nprint(f\"NumPy version: {np.__version__}\")\nprint(f\"Pandas version: {pd.__version__}\")",
   "id": "cell-imports"
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "## Implementation: Feature Extraction vs End-to-End Learning\n\nIn this section, we'll implement both approaches using a simplified neural network. We'll demonstrate the concepts using NumPy and scikit-learn to show the fundamental differences between the two approaches.\n\n### Scenario Setup\n\nWe'll work with the MNIST digits dataset and simulate a transfer learning scenario:\n1. First, we'll create a \"pre-trained\" feature extractor\n2. Then compare feature extraction vs end-to-end learning for a classification task",
   "id": "cell-visualization"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Load and prepare the dataset\nfrom sklearn.datasets import load_digits\n\n# Load digits dataset (8x8 images of digits 0-9)\ndigits = load_digits()\nX, y = digits.data, digits.target\n\nprint(f\"Dataset shape: {X.shape}\")\nprint(f\"Number of classes: {len(np.unique(y))}\")\nprint(f\"Sample image shape: {digits.images[0].shape}\")\n\n# Split into train and test sets\nX_train, X_test, y_train, y_test = train_test_split(\n    X, y, test_size=0.3, random_state=42, stratify=y\n)\n\n# Normalize the data\nscaler = StandardScaler()\nX_train_scaled = scaler.fit_transform(X_train)\nX_test_scaled = scaler.transform(X_test)\n\nprint(f\"\\nTraining samples: {X_train_scaled.shape[0]}\")\nprint(f\"Test samples: {X_test_scaled.shape[0]}\")\n\n# Visualize some samples\nfig, axes = plt.subplots(2, 5, figsize=(12, 5))\nfor i, ax in enumerate(axes.flat):\n    ax.imshow(digits.images[i], cmap='gray')\n    ax.set_title(f'Label: {digits.target[i]}')\n    ax.axis('off')\nplt.suptitle('Sample Digit Images', fontsize=14, y=1.02)\nplt.tight_layout()\nplt.show()",
   "id": "cell-examples"
  },
  {
   "cell_type": "markdown",
   "source": "### Simple Neural Network Implementation\n\nLet's create a simple neural network class that allows us to freeze/unfreeze layers:",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "class SimpleNeuralNetwork:\n    \"\"\"\n    A simple 2-layer neural network with freeze/unfreeze capability.\n    This simulates a pre-trained model with feature extraction.\n    \"\"\"\n    def __init__(self, input_dim, hidden_dim, output_dim, freeze_features=False):\n        self.freeze_features = freeze_features\n        \n        # Initialize weights (simulating a \"pre-trained\" model)\n        self.W1 = np.random.randn(input_dim, hidden_dim) * 0.01\n        self.b1 = np.zeros((1, hidden_dim))\n        \n        # Classifier weights (always trainable)\n        self.W2 = np.random.randn(hidden_dim, output_dim) * 0.01\n        self.b2 = np.zeros((1, output_dim))\n        \n        # Store original weights if frozen\n        if freeze_features:\n            self.W1_frozen = self.W1.copy()\n            self.b1_frozen = self.b1.copy()\n    \n    def relu(self, Z):\n        return np.maximum(0, Z)\n    \n    def softmax(self, Z):\n        exp_Z = np.exp(Z - np.max(Z, axis=1, keepdims=True))\n        return exp_Z / np.sum(exp_Z, axis=1, keepdims=True)\n    \n    def forward(self, X):\n        # Feature extraction layer (can be frozen)\n        self.Z1 = np.dot(X, self.W1) + self.b1\n        self.A1 = self.relu(self.Z1)\n        \n        # Classifier layer (always trainable)\n        self.Z2 = np.dot(self.A1, self.W2) + self.b2\n        self.A2 = self.softmax(self.Z2)\n        \n        return self.A2\n    \n    def backward(self, X, y, learning_rate=0.01):\n        m = X.shape[0]\n        \n        # Convert labels to one-hot\n        y_onehot = np.zeros((m, self.W2.shape[1]))\n        y_onehot[np.arange(m), y] = 1\n        \n        # Backward pass for classifier (always updated)\n        dZ2 = self.A2 - y_onehot\n        dW2 = np.dot(self.A1.T, dZ2) / m\n        db2 = np.sum(dZ2, axis=0, keepdims=True) / m\n        \n        # Update classifier weights\n        self.W2 -= learning_rate * dW2\n        self.b2 -= learning_rate * db2\n        \n        # Backward pass for feature extractor (only if not frozen)\n        if not self.freeze_features:\n            dA1 = np.dot(dZ2, self.W2.T)\n            dZ1 = dA1 * (self.Z1 > 0)  # ReLU derivative\n            dW1 = np.dot(X.T, dZ1) / m\n            db1 = np.sum(dZ1, axis=0, keepdims=True) / m\n            \n            # Update feature extractor weights\n            self.W1 -= learning_rate * dW1\n            self.b1 -= learning_rate * db1\n        else:\n            # Keep features frozen\n            self.W1 = self.W1_frozen.copy()\n            self.b1 = self.b1_frozen.copy()\n    \n    def compute_loss(self, y_pred, y_true):\n        m = y_true.shape[0]\n        log_likelihood = -np.log(y_pred[range(m), y_true] + 1e-8)\n        loss = np.sum(log_likelihood) / m\n        return loss\n    \n    def train(self, X_train, y_train, X_val, y_val, epochs=100, learning_rate=0.01, verbose=True):\n        train_losses = []\n        val_losses = []\n        train_accs = []\n        val_accs = []\n        \n        start_time = time.time()\n        \n        for epoch in range(epochs):\n            # Forward pass\n            y_pred = self.forward(X_train)\n            \n            # Compute loss\n            train_loss = self.compute_loss(y_pred, y_train)\n            \n            # Backward pass and update\n            self.backward(X_train, y_train, learning_rate)\n            \n            # Validation\n            y_val_pred = self.forward(X_val)\n            val_loss = self.compute_loss(y_val_pred, y_val)\n            \n            # Compute accuracies\n            train_acc = accuracy_score(y_train, np.argmax(y_pred, axis=1))\n            val_acc = accuracy_score(y_val, np.argmax(y_val_pred, axis=1))\n            \n            train_losses.append(train_loss)\n            val_losses.append(val_loss)\n            train_accs.append(train_acc)\n            val_accs.append(val_acc)\n            \n            if verbose and (epoch + 1) % 20 == 0:\n                print(f\"Epoch {epoch+1}/{epochs} - Loss: {train_loss:.4f} - Acc: {train_acc:.4f} - Val Loss: {val_loss:.4f} - Val Acc: {val_acc:.4f}\")\n        \n        training_time = time.time() - start_time\n        \n        return {\n            'train_losses': train_losses,\n            'val_losses': val_losses,\n            'train_accs': train_accs,\n            'val_accs': val_accs,\n            'training_time': training_time\n        }\n    \n    def predict(self, X):\n        y_pred = self.forward(X)\n        return np.argmax(y_pred, axis=1)\n\nprint(\"SimpleNeuralNetwork class defined successfully!\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# Create comprehensive comparison visualizations\nfig, axes = plt.subplots(2, 2, figsize=(14, 10))\n\n# Plot 1: Training Loss Comparison\naxes[0, 0].plot(history_frozen['train_losses'], label='Feature Extraction', linewidth=2, alpha=0.8)\naxes[0, 0].plot(history_unfrozen['train_losses'], label='End-to-End', linewidth=2, alpha=0.8)\naxes[0, 0].set_xlabel('Epoch', fontsize=11)\naxes[0, 0].set_ylabel('Training Loss', fontsize=11)\naxes[0, 0].set_title('Training Loss Comparison', fontsize=12, fontweight='bold')\naxes[0, 0].legend()\naxes[0, 0].grid(True, alpha=0.3)\n\n# Plot 2: Validation Loss Comparison\naxes[0, 1].plot(history_frozen['val_losses'], label='Feature Extraction', linewidth=2, alpha=0.8)\naxes[0, 1].plot(history_unfrozen['val_losses'], label='End-to-End', linewidth=2, alpha=0.8)\naxes[0, 1].set_xlabel('Epoch', fontsize=11)\naxes[0, 1].set_ylabel('Validation Loss', fontsize=11)\naxes[0, 1].set_title('Validation Loss Comparison', fontsize=12, fontweight='bold')\naxes[0, 1].legend()\naxes[0, 1].grid(True, alpha=0.3)\n\n# Plot 3: Training Accuracy Comparison\naxes[1, 0].plot(history_frozen['train_accs'], label='Feature Extraction', linewidth=2, alpha=0.8)\naxes[1, 0].plot(history_unfrozen['train_accs'], label='End-to-End', linewidth=2, alpha=0.8)\naxes[1, 0].set_xlabel('Epoch', fontsize=11)\naxes[1, 0].set_ylabel('Training Accuracy', fontsize=11)\naxes[1, 0].set_title('Training Accuracy Comparison', fontsize=12, fontweight='bold')\naxes[1, 0].legend()\naxes[1, 0].grid(True, alpha=0.3)\n\n# Plot 4: Validation Accuracy Comparison\naxes[1, 1].plot(history_frozen['val_accs'], label='Feature Extraction', linewidth=2, alpha=0.8)\naxes[1, 1].plot(history_unfrozen['val_accs'], label='End-to-End', linewidth=2, alpha=0.8)\naxes[1, 1].set_xlabel('Epoch', fontsize=11)\naxes[1, 1].set_ylabel('Validation Accuracy', fontsize=11)\naxes[1, 1].set_title('Validation Accuracy Comparison', fontsize=12, fontweight='bold')\naxes[1, 1].legend()\naxes[1, 1].grid(True, alpha=0.3)\n\nplt.tight_layout()\nplt.show()\n\n# Summary comparison table\ncomparison_data = {\n    'Metric': ['Training Time (s)', 'Final Test Accuracy', 'Final Train Accuracy', 'Trainable Layers'],\n    'Feature Extraction': [\n        f\"{history_frozen['training_time']:.2f}\",\n        f\"{test_acc_frozen:.4f}\",\n        f\"{history_frozen['train_accs'][-1]:.4f}\",\n        \"Classifier only\"\n    ],\n    'End-to-End': [\n        f\"{history_unfrozen['training_time']:.2f}\",\n        f\"{test_acc_unfrozen:.4f}\",\n        f\"{history_unfrozen['train_accs'][-1]:.4f}\",\n        \"All layers\"\n    ]\n}\n\ncomparison_df = pd.DataFrame(comparison_data)\nprint(\"\\n\" + \"=\"*80)\nprint(\"COMPREHENSIVE COMPARISON\")\nprint(\"=\"*80)\nprint(comparison_df.to_string(index=False))\nprint(\"=\"*80)\n\n# Calculate speedup\nspeedup = history_unfrozen['training_time'] / history_frozen['training_time']\nprint(f\"\\nSpeedup (Feature Extraction vs End-to-End): {speedup:.2f}x faster\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "### Comparison and Visualization\n\nLet's visualize the training dynamics and compare both approaches:",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# Approach 2: End-to-End Learning (Unfrozen Backbone)\nprint(\"=\" * 60)\nprint(\"APPROACH 2: End-to-End Learning (Unfrozen Backbone)\")\nprint(\"=\" * 60)\n\n# Create model with unfrozen features\nmodel_unfrozen = SimpleNeuralNetwork(\n    input_dim=X_train_scaled.shape[1],\n    hidden_dim=128,\n    output_dim=10,\n    freeze_features=False  # All layers are trainable\n)\n\n# Train the model\nhistory_unfrozen = model_unfrozen.train(\n    X_train_scaled, y_train,\n    X_test_scaled, y_test,\n    epochs=100,\n    learning_rate=0.1,\n    verbose=True\n)\n\n# Evaluate on test set\ny_pred_unfrozen = model_unfrozen.predict(X_test_scaled)\ntest_acc_unfrozen = accuracy_score(y_test, y_pred_unfrozen)\n\nprint(f\"\\n{'='*60}\")\nprint(f\"End-to-End Learning Results:\")\nprint(f\"{'='*60}\")\nprint(f\"Training Time: {history_unfrozen['training_time']:.2f} seconds\")\nprint(f\"Final Test Accuracy: {test_acc_unfrozen:.4f}\")\nprint(f\"Trainable Parameters: All layers (W1, b1, W2, b2)\")\nprint(f\"{'='*60}\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "### Approach 2: End-to-End Learning (Unfrozen Backbone)\n\nNow let's train a model with all layers unfrozen:",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# Approach 1: Feature Extraction (Frozen Backbone)\nprint(\"=\" * 60)\nprint(\"APPROACH 1: Feature Extraction (Frozen Backbone)\")\nprint(\"=\" * 60)\n\n# Create model with frozen features\nmodel_frozen = SimpleNeuralNetwork(\n    input_dim=X_train_scaled.shape[1],\n    hidden_dim=128,\n    output_dim=10,\n    freeze_features=True\n)\n\n# Train the model\nhistory_frozen = model_frozen.train(\n    X_train_scaled, y_train,\n    X_test_scaled, y_test,\n    epochs=100,\n    learning_rate=0.1,\n    verbose=True\n)\n\n# Evaluate on test set\ny_pred_frozen = model_frozen.predict(X_test_scaled)\ntest_acc_frozen = accuracy_score(y_test, y_pred_frozen)\n\nprint(f\"\\n{'='*60}\")\nprint(f\"Feature Extraction Results:\")\nprint(f\"{'='*60}\")\nprint(f\"Training Time: {history_frozen['training_time']:.2f} seconds\")\nprint(f\"Final Test Accuracy: {test_acc_frozen:.4f}\")\nprint(f\"Trainable Parameters: Only classifier layer (W2, b2)\")\nprint(f\"{'='*60}\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "### Approach 1: Feature Extraction (Frozen Backbone)\n\nLet's train a model with frozen feature extraction layers:",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Hands-On Activity\n\n### Challenge: Progressive Unfreezing\n\nIn this activity, you'll implement **progressive unfreezing**, a hybrid approach that combines the benefits of both feature extraction and end-to-end learning.\n\n**Task:**\n1. Start with feature extraction (frozen features) and train for 50 epochs\n2. Unfreeze all layers and continue training for 50 more epochs with a lower learning rate\n3. Compare the results with both pure approaches\n\n**Why Progressive Unfreezing?**\n- Prevents catastrophic forgetting of pre-trained features\n- Allows the classifier to stabilize before fine-tuning the backbone\n- Often achieves better performance than either pure approach\n\n**Instructions:**\nComplete the code below to implement progressive unfreezing:",
   "id": "cell-activity"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Progressive Unfreezing Implementation\nprint(\"=\" * 60)\nprint(\"PROGRESSIVE UNFREEZING APPROACH\")\nprint(\"=\" * 60)\n\n# Phase 1: Feature Extraction (50 epochs)\nprint(\"\\nPhase 1: Training with frozen features (50 epochs)...\")\nmodel_progressive = SimpleNeuralNetwork(\n    input_dim=X_train_scaled.shape[1],\n    hidden_dim=128,\n    output_dim=10,\n    freeze_features=True\n)\n\nhistory_phase1 = model_progressive.train(\n    X_train_scaled, y_train,\n    X_test_scaled, y_test,\n    epochs=50,\n    learning_rate=0.1,\n    verbose=False\n)\n\nprint(f\"Phase 1 completed - Val Accuracy: {history_phase1['val_accs'][-1]:.4f}\")\n\n# Phase 2: Unfreeze and continue training\nprint(\"\\nPhase 2: Unfreezing all layers and fine-tuning (50 epochs)...\")\nmodel_progressive.freeze_features = False  # Unfreeze the backbone\n\nhistory_phase2 = model_progressive.train(\n    X_train_scaled, y_train,\n    X_test_scaled, y_test,\n    epochs=50,\n    learning_rate=0.01,  # Lower learning rate for fine-tuning\n    verbose=False\n)\n\nprint(f\"Phase 2 completed - Val Accuracy: {history_phase2['val_accs'][-1]:.4f}\")\n\n# Combine histories\nhistory_progressive = {\n    'train_losses': history_phase1['train_losses'] + history_phase2['train_losses'],\n    'val_losses': history_phase1['val_losses'] + history_phase2['val_losses'],\n    'train_accs': history_phase1['train_accs'] + history_phase2['train_accs'],\n    'val_accs': history_phase1['val_accs'] + history_phase2['val_accs'],\n    'training_time': history_phase1['training_time'] + history_phase2['training_time']\n}\n\n# Evaluate final performance\ny_pred_progressive = model_progressive.predict(X_test_scaled)\ntest_acc_progressive = accuracy_score(y_test, y_pred_progressive)\n\nprint(f\"\\n{'='*60}\")\nprint(f\"Progressive Unfreezing Results:\")\nprint(f\"{'='*60}\")\nprint(f\"Total Training Time: {history_progressive['training_time']:.2f} seconds\")\nprint(f\"Final Test Accuracy: {test_acc_progressive:.4f}\")\nprint(f\"{'='*60}\")\n\n# Visualize progressive unfreezing\nfig, axes = plt.subplots(1, 2, figsize=(14, 5))\n\n# Plot validation accuracy with phase transition\naxes[0].plot(history_progressive['val_accs'], linewidth=2, label='Progressive Unfreezing')\naxes[0].axvline(x=50, color='red', linestyle='--', linewidth=2, alpha=0.7, label='Unfreeze Point')\naxes[0].set_xlabel('Epoch', fontsize=11)\naxes[0].set_ylabel('Validation Accuracy', fontsize=11)\naxes[0].set_title('Progressive Unfreezing: Validation Accuracy', fontsize=12, fontweight='bold')\naxes[0].legend()\naxes[0].grid(True, alpha=0.3)\n\n# Compare all three approaches\naxes[1].plot(history_frozen['val_accs'], label='Feature Extraction', linewidth=2, alpha=0.8)\naxes[1].plot(history_unfrozen['val_accs'], label='End-to-End', linewidth=2, alpha=0.8)\naxes[1].plot(history_progressive['val_accs'], label='Progressive Unfreezing', linewidth=2, alpha=0.8)\naxes[1].set_xlabel('Epoch', fontsize=11)\naxes[1].set_ylabel('Validation Accuracy', fontsize=11)\naxes[1].set_title('All Approaches Compared', fontsize=12, fontweight='bold')\naxes[1].legend()\naxes[1].grid(True, alpha=0.3)\n\nplt.tight_layout()\nplt.show()\n\n# Final comparison of all three approaches\nfinal_comparison = {\n    'Approach': ['Feature Extraction', 'End-to-End', 'Progressive Unfreezing'],\n    'Test Accuracy': [f\"{test_acc_frozen:.4f}\", f\"{test_acc_unfrozen:.4f}\", f\"{test_acc_progressive:.4f}\"],\n    'Training Time (s)': [\n        f\"{history_frozen['training_time']:.2f}\",\n        f\"{history_unfrozen['training_time']:.2f}\",\n        f\"{history_progressive['training_time']:.2f}\"\n    ],\n    'Best For': [\n        'Limited data, similar domains',\n        'Large data, dissimilar domains',\n        'Balance of performance & stability'\n    ]\n}\n\nfinal_df = pd.DataFrame(final_comparison)\nprint(\"\\n\" + \"=\"*100)\nprint(\"FINAL COMPARISON: ALL THREE APPROACHES\")\nprint(\"=\"*100)\nprint(final_df.to_string(index=False))\nprint(\"=\"*100)",
   "id": "cell-activity-code"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Key Takeaways\n\n- **Feature Extraction** freezes pre-trained layers and only trains the classifier, making it fast and efficient for small datasets or similar domains. It's ideal when computational resources are limited.\n\n- **End-to-End Learning** (fine-tuning) updates all network weights, achieving better performance when you have sufficient data and the target domain differs from the pre-training domain. It requires more computational resources and careful tuning.\n\n- **Progressive Unfreezing** combines both approaches: start with frozen features to stabilize the classifier, then gradually unfreeze layers with lower learning rates. This hybrid strategy often provides the best balance between performance and stability.\n\n- **Trade-offs to Consider**: Feature extraction trains faster but may underperform on dissimilar domains. End-to-end learning achieves higher accuracy but risks overfitting with limited data. Choose based on your dataset size, domain similarity, and computational budget.\n\n- **Learning Rate Strategy**: Use standard learning rates (e.g., 0.001-0.1) for feature extraction. For end-to-end learning, use lower rates (e.g., 0.0001-0.001) to prevent catastrophic forgetting of pre-trained features.\n\n- **Practical Rule of Thumb**: \n  - Dataset < 1,000 samples → Feature extraction only\n  - Dataset 1,000-10,000 samples → Progressive unfreezing\n  - Dataset > 10,000 samples → End-to-end learning or progressive unfreezing",
   "id": "cell-takeaways"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Further Resources\n\n### Academic Papers\n- [Deep Residual Learning for Image Recognition (ResNet)](https://arxiv.org/abs/1512.03385) - Seminal paper on deep learning architectures commonly used for transfer learning\n- [How transferable are features in deep neural networks?](https://arxiv.org/abs/1411.1792) - Yosinski et al.'s analysis of feature transferability across layers\n\n### Tutorials and Guides\n- [PyTorch Transfer Learning Tutorial](https://pytorch.org/tutorials/beginner/transfer_learning_tutorial.html) - Official PyTorch guide with practical examples\n- [Fast.ai Course - Transfer Learning](https://course.fast.ai/) - Practical deep learning course emphasizing transfer learning best practices\n- [TensorFlow Transfer Learning Guide](https://www.tensorflow.org/tutorials/images/transfer_learning) - Comprehensive TensorFlow/Keras implementation\n\n### Blog Posts\n- [Feature Extraction vs Fine-Tuning](https://cs231n.github.io/transfer-learning/) - Stanford CS231n notes on transfer learning strategies\n- [A Comprehensive Guide to Transfer Learning](https://builtin.com/data-science/transfer-learning) - Practical guide with real-world examples\n\n### Tools and Libraries\n- [torchvision.models](https://pytorch.org/vision/stable/models.html) - Pre-trained models in PyTorch\n- [Hugging Face Transformers](https://huggingface.co/docs/transformers/index) - Pre-trained models for NLP and computer vision\n- [TensorFlow Hub](https://www.tensorflow.org/hub) - Repository of pre-trained models\n\n### Practice Datasets\n- [ImageNet](https://www.image-net.org/) - Large-scale image classification benchmark\n- [CIFAR-10/100](https://www.cs.toronto.edu/~kriz/cifar.html) - Small image classification datasets perfect for experimentation\n- [Stanford Dogs Dataset](http://vision.stanford.edu/aditya86/ImageNetDogs/) - Fine-grained classification task ideal for transfer learning",
   "id": "cell-resources"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}