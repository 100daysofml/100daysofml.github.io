{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Day 65: Transfer Learning with Pre-trained Models\n",
    "\n",
    "Transfer learning is one of the most powerful techniques in modern deep learning, enabling us to leverage knowledge from models trained on large datasets and apply it to new, often smaller datasets. This approach has revolutionized how we approach machine learning problems, particularly in computer vision and natural language processing.\n",
    "\n",
    "## What is Transfer Learning?\n",
    "\n",
    "Transfer learning is a machine learning technique where a model developed for one task is reused as the starting point for a model on a second task. Instead of training a deep neural network from scratch, which requires massive amounts of data and computational resources, we can take a pre-trained model that has already learned useful features from a large dataset and adapt it to our specific problem.\n",
    "\n",
    "The intuition behind transfer learning is simple yet powerful: features learned from one task can be useful for another related task. For example, a model trained to recognize everyday objects has learned to detect edges, shapes, textures, and patternsâ€”features that are useful for many other computer vision tasks.\n",
    "\n",
    "## Why Transfer Learning Matters\n",
    "\n",
    "Transfer learning addresses several key challenges in machine learning:\n",
    "\n",
    "1. **Limited Data**: Many real-world problems don't have millions of labeled examples. Transfer learning allows us to achieve good performance even with relatively small datasets.\n",
    "\n",
    "2. **Computational Efficiency**: Training deep neural networks from scratch can take days or weeks on powerful GPUs. Transfer learning dramatically reduces training time.\n",
    "\n",
    "3. **Better Generalization**: Pre-trained models have learned robust features from diverse data, often leading to better generalization on new tasks.\n",
    "\n",
    "4. **Democratization of AI**: Transfer learning makes state-of-the-art models accessible to researchers and practitioners who don't have access to massive computational resources.\n",
    "\n",
    "## Learning Objectives\n",
    "\n",
    "By the end of this lesson, you will be able to:\n",
    "\n",
    "- Understand the fundamental concepts of transfer learning\n",
    "- Distinguish between feature extraction and fine-tuning approaches\n",
    "- Load and use pre-trained models from popular frameworks\n",
    "- Adapt pre-trained models to new classification tasks\n",
    "- Evaluate the performance of transfer learning models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Theory: Understanding Transfer Learning\n",
    "\n",
    "### The Mathematical Foundation\n",
    "\n",
    "In traditional supervised learning, we aim to learn a function $f: X \\rightarrow Y$ that maps inputs $X$ from a source domain $D_S$ to outputs $Y$ based on a task $T_S$. The model learns parameters $\\theta$ by minimizing a loss function:\n",
    "\n",
    "$$\\theta^* = \\arg\\min_{\\theta} \\mathcal{L}(f(X; \\theta), Y)$$\n",
    "\n",
    "In transfer learning, we leverage knowledge from a source domain $D_S$ and source task $T_S$ to improve learning in a target domain $D_T$ and target task $T_T$. The key assumption is that the source and target domains/tasks are related but not identical.\n",
    "\n",
    "### Types of Transfer Learning\n",
    "\n",
    "**1. Feature Extraction (Frozen Layers)**\n",
    "\n",
    "In feature extraction, we use the pre-trained model as a fixed feature extractor. The convolutional base of a pre-trained network is frozen (weights are not updated), and we only train a new classifier on top:\n",
    "\n",
    "$$h = f_{pretrained}(x; \\theta_{frozen})$$\n",
    "$$\\hat{y} = g(h; \\theta_{new})$$\n",
    "\n",
    "where $f_{pretrained}$ represents the frozen pre-trained layers, and $g$ represents the new trainable layers.\n",
    "\n",
    "**2. Fine-Tuning (Unfrozen Layers)**\n",
    "\n",
    "In fine-tuning, we unfreeze some or all of the pre-trained layers and continue training with a small learning rate. This allows the model to adapt the learned features to our specific task:\n",
    "\n",
    "$$\\theta_{final} = \\theta_{pretrained} + \\Delta\\theta$$\n",
    "\n",
    "where $\\Delta\\theta$ represents the updates to the pre-trained weights, typically with a learning rate $\\alpha_{fine-tune} \\ll \\alpha_{initial}$.\n",
    "\n",
    "### Layer-wise Feature Hierarchy\n",
    "\n",
    "Deep neural networks learn hierarchical features:\n",
    "\n",
    "- **Early layers**: Learn generic, low-level features (edges, colors, textures)\n",
    "- **Middle layers**: Learn intermediate features (shapes, patterns)\n",
    "- **Late layers**: Learn high-level, task-specific features\n",
    "\n",
    "This hierarchy is why transfer learning works: early and middle layers learn features that are broadly applicable across many tasks.\n",
    "\n",
    "### When to Use Which Approach\n",
    "\n",
    "The choice between feature extraction and fine-tuning depends on:\n",
    "\n",
    "1. **Dataset Size**:\n",
    "   - Small dataset: Use feature extraction (avoid overfitting)\n",
    "   - Large dataset: Fine-tuning is safer\n",
    "\n",
    "2. **Similarity to Source Task**:\n",
    "   - Very similar: Fine-tune top layers only\n",
    "   - Very different: May need to fine-tune more layers or use as feature extractor\n",
    "\n",
    "3. **Computational Resources**:\n",
    "   - Limited: Feature extraction (faster)\n",
    "   - Abundant: Fine-tuning (potentially better performance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Popular Pre-trained Models\n",
    "\n",
    "Several architectures have become standard for transfer learning:\n",
    "\n",
    "### VGG (Visual Geometry Group)\n",
    "\n",
    "VGG networks are known for their simplicity and depth. VGG16 and VGG19 use small 3x3 convolutional filters stacked deeply. The architecture is:\n",
    "\n",
    "$$\\text{Input} \\rightarrow \\text{Conv Blocks} \\rightarrow \\text{Fully Connected} \\rightarrow \\text{Softmax}$$\n",
    "\n",
    "where each Conv Block consists of multiple 3x3 convolutions followed by max pooling.\n",
    "\n",
    "### ResNet (Residual Networks)\n",
    "\n",
    "ResNet introduced skip connections to enable training very deep networks. A residual block computes:\n",
    "\n",
    "$$y = F(x, \\{W_i\\}) + x$$\n",
    "\n",
    "where $F(x, \\{W_i\\})$ represents the residual mapping and $x$ is the identity shortcut connection.\n",
    "\n",
    "### MobileNet\n",
    "\n",
    "MobileNet uses depthwise separable convolutions for efficiency:\n",
    "\n",
    "$$\\text{Depthwise Conv} + \\text{Pointwise Conv} \\approx \\frac{1}{N} + \\frac{1}{D_K^2}$$\n",
    "\n",
    "This reduces computation compared to standard convolutions while maintaining accuracy.\n",
    "\n",
    "### Inception/GoogLeNet\n",
    "\n",
    "Inception modules process the input at multiple scales simultaneously using different kernel sizes, then concatenate the results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Python Implementation: Setting Up\n",
    "\n",
    "Let's start by importing the necessary libraries and setting up our environment for transfer learning experiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# TensorFlow and Keras for deep learning\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.applications import VGG16, ResNet50, MobileNetV2\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# Display versions\n",
    "print(f\"TensorFlow version: {tf.__version__}\")\n",
    "print(f\"Keras version: {keras.__version__}\")\n",
    "print(f\"NumPy version: {np.__version__}\")\n",
    "\n",
    "# Set plotting style\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette(\"husl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing Transfer Learning Concepts\n",
    "\n",
    "Let's create a visualization to understand how transfer learning works and the difference between feature extraction and fine-tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "from matplotlib.patches import FancyBboxPatch, FancyArrowPatch\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 6))\n",
    "\n",
    "# Common elements\n",
    "layer_height = 0.15\n",
    "layer_width = 0.6\n",
    "start_x = 0.2\n",
    "\n",
    "# Function to draw a layer\n",
    "def draw_layer(ax, y_pos, label, color, frozen=False):\n",
    "    rect = FancyBboxPatch((start_x, y_pos), layer_width, layer_height, \n",
    "                          boxstyle=\"round,pad=0.01\", \n",
    "                          edgecolor='black', \n",
    "                          facecolor=color, \n",
    "                          linewidth=2 if frozen else 1,\n",
    "                          linestyle='--' if frozen else '-')\n",
    "    ax.add_patch(rect)\n",
    "    ax.text(start_x + layer_width/2, y_pos + layer_height/2, label, \n",
    "           ha='center', va='center', fontsize=9, weight='bold')\n",
    "    if frozen:\n",
    "        ax.text(start_x + layer_width + 0.05, y_pos + layer_height/2, 'ðŸ”’', \n",
    "               ha='left', va='center', fontsize=12)\n",
    "\n",
    "# Subplot 1: Traditional Training\n",
    "ax1 = axes[0]\n",
    "ax1.set_xlim(0, 1)\n",
    "ax1.set_ylim(0, 1)\n",
    "ax1.axis('off')\n",
    "ax1.set_title('Traditional Training\\n(From Scratch)', fontsize=12, weight='bold')\n",
    "\n",
    "y_positions = [0.7, 0.52, 0.34, 0.16]\n",
    "labels = ['Input Layer', 'Conv Layers\\n(Random Init)', 'Dense Layers\\n(Random Init)', 'Output Layer']\n",
    "colors = ['lightblue', 'lightcoral', 'lightcoral', 'lightgreen']\n",
    "\n",
    "for y, label, color in zip(y_positions, labels, colors):\n",
    "    draw_layer(ax1, y, label, color, frozen=False)\n",
    "\n",
    "ax1.text(0.5, 0.05, 'All layers trained\\nRequires large dataset', \n",
    "        ha='center', fontsize=9, style='italic')\n",
    "\n",
    "# Subplot 2: Feature Extraction\n",
    "ax2 = axes[1]\n",
    "ax2.set_xlim(0, 1)\n",
    "ax2.set_ylim(0, 1)\n",
    "ax2.axis('off')\n",
    "ax2.set_title('Transfer Learning\\n(Feature Extraction)', fontsize=12, weight='bold')\n",
    "\n",
    "labels2 = ['Input Layer', 'Pre-trained\\nConv Layers', 'New Dense\\nLayers', 'New Output\\nLayer']\n",
    "colors2 = ['lightblue', 'gold', 'lightcoral', 'lightgreen']\n",
    "frozen2 = [False, True, False, False]\n",
    "\n",
    "for y, label, color, frz in zip(y_positions, labels2, colors2, frozen2):\n",
    "    draw_layer(ax2, y, label, color, frozen=frz)\n",
    "\n",
    "ax2.text(0.5, 0.05, 'Pre-trained layers frozen\\nOnly train new layers', \n",
    "        ha='center', fontsize=9, style='italic')\n",
    "\n",
    "# Subplot 3: Fine-tuning\n",
    "ax3 = axes[2]\n",
    "ax3.set_xlim(0, 1)\n",
    "ax3.set_ylim(0, 1)\n",
    "ax3.axis('off')\n",
    "ax3.set_title('Transfer Learning\\n(Fine-tuning)', fontsize=12, weight='bold')\n",
    "\n",
    "labels3 = ['Input Layer', 'Pre-trained\\nConv Layers', 'New Dense\\nLayers', 'New Output\\nLayer']\n",
    "colors3 = ['lightblue', 'lightyellow', 'lightcoral', 'lightgreen']\n",
    "frozen3 = [False, False, False, False]\n",
    "\n",
    "for y, label, color, frz in zip(y_positions, labels3, colors3, frozen3):\n",
    "    draw_layer(ax3, y, label, color, frozen=frz)\n",
    "\n",
    "ax3.text(0.5, 0.05, 'All layers trainable\\nLow learning rate for pre-trained', \n",
    "        ha='center', fontsize=9, style='italic')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('transfer_learning_approaches.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nKey Differences:\")\n",
    "print(\"1. Traditional: All weights learned from scratch (requires lots of data)\")\n",
    "print(\"2. Feature Extraction: Use pre-trained features, train only new layers (fast, small datasets)\")\n",
    "print(\"3. Fine-tuning: Adapt pre-trained weights to new task (best performance, moderate datasets)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Pre-trained Models\n",
    "\n",
    "Let's explore how to load popular pre-trained models and examine their architectures. We'll use models trained on ImageNet, a dataset of 1.4 million images across 1000 categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pre-trained models (without top classification layer)\n",
    "# We set include_top=False to remove the final classification layer\n",
    "# This allows us to add our own classifier for our specific task\n",
    "\n",
    "print(\"Loading pre-trained models...\\n\")\n",
    "\n",
    "# VGG16: 16-layer network (13 conv + 3 FC)\n",
    "vgg_base = VGG16(weights='imagenet', \n",
    "                 include_top=False, \n",
    "                 input_shape=(224, 224, 3))\n",
    "print(f\"VGG16 loaded:\")\n",
    "print(f\"  - Total layers: {len(vgg_base.layers)}\")\n",
    "print(f\"  - Trainable parameters: {vgg_base.count_params():,}\")\n",
    "print(f\"  - Output shape: {vgg_base.output_shape}\\n\")\n",
    "\n",
    "# ResNet50: 50-layer residual network\n",
    "resnet_base = ResNet50(weights='imagenet', \n",
    "                       include_top=False, \n",
    "                       input_shape=(224, 224, 3))\n",
    "print(f\"ResNet50 loaded:\")\n",
    "print(f\"  - Total layers: {len(resnet_base.layers)}\")\n",
    "print(f\"  - Trainable parameters: {resnet_base.count_params():,}\")\n",
    "print(f\"  - Output shape: {resnet_base.output_shape}\\n\")\n",
    "\n",
    "# MobileNetV2: Efficient architecture for mobile devices\n",
    "mobilenet_base = MobileNetV2(weights='imagenet', \n",
    "                            include_top=False, \n",
    "                            input_shape=(224, 224, 3))\n",
    "print(f\"MobileNetV2 loaded:\")\n",
    "print(f\"  - Total layers: {len(mobilenet_base.layers)}\")\n",
    "print(f\"  - Trainable parameters: {mobilenet_base.count_params():,}\")\n",
    "print(f\"  - Output shape: {mobilenet_base.output_shape}\\n\")\n",
    "\n",
    "print(\"All models successfully loaded!\")\n",
    "print(\"\\nNote: These models are pre-trained on ImageNet (1000 classes)\")\n",
    "print(\"We'll adapt them to our specific classification task.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing Data for Transfer Learning\n",
    "\n",
    "For this example, we'll use a subset of the CIFAR-10 dataset to demonstrate transfer learning. In practice, you would use your own domain-specific dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load CIFAR-10 dataset for demonstration\n",
    "# In practice, you would load your own dataset\n",
    "\n",
    "print(\"Loading CIFAR-10 dataset...\")\n",
    "(x_train_full, y_train_full), (x_test_full, y_test_full) = keras.datasets.cifar10.load_data()\n",
    "\n",
    "# Class names for CIFAR-10\n",
    "class_names = ['airplane', 'automobile', 'bird', 'cat', 'deer', \n",
    "               'dog', 'frog', 'horse', 'ship', 'truck']\n",
    "\n",
    "# For demonstration, let's use a binary classification task:\n",
    "# Classify cats (class 3) vs dogs (class 5)\n",
    "# This simulates a real-world scenario where you have a specific task\n",
    "\n",
    "# Filter for cats and dogs only\n",
    "train_mask = np.isin(y_train_full, [3, 5]).flatten()\n",
    "test_mask = np.isin(y_test_full, [3, 5]).flatten()\n",
    "\n",
    "x_train = x_train_full[train_mask]\n",
    "y_train = y_train_full[train_mask]\n",
    "x_test = x_test_full[test_mask]\n",
    "y_test = y_test_full[test_mask]\n",
    "\n",
    "# Convert labels: cat=0, dog=1\n",
    "y_train = (y_train == 5).astype(int)\n",
    "y_test = (y_test == 5).astype(int)\n",
    "\n",
    "# Use only a subset to simulate limited data scenario\n",
    "n_samples = 1000\n",
    "indices = np.random.choice(len(x_train), n_samples, replace=False)\n",
    "x_train_small = x_train[indices]\n",
    "y_train_small = y_train[indices]\n",
    "\n",
    "print(f\"\\nDataset prepared:\")\n",
    "print(f\"  - Training samples: {len(x_train_small)}\")\n",
    "print(f\"  - Test samples: {len(x_test)}\")\n",
    "print(f\"  - Original image shape: {x_train_small.shape[1:]}\")\n",
    "print(f\"  - Task: Binary classification (Cat vs Dog)\")\n",
    "print(f\"\\nClass distribution in training set:\")\n",
    "print(f\"  - Cats: {np.sum(y_train_small == 0)}\")\n",
    "print(f\"  - Dogs: {np.sum(y_train_small == 1)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing the Dataset\n",
    "\n",
    "Let's visualize some examples from our dataset to understand what we're working with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize sample images\n",
    "fig, axes = plt.subplots(2, 8, figsize=(16, 4))\n",
    "fig.suptitle('Sample Images from Our Dataset', fontsize=14, weight='bold')\n",
    "\n",
    "# Get 8 cats and 8 dogs\n",
    "cat_indices = np.where(y_train_small == 0)[0][:8]\n",
    "dog_indices = np.where(y_train_small == 1)[0][:8]\n",
    "\n",
    "for i, idx in enumerate(cat_indices):\n",
    "    axes[0, i].imshow(x_train_small[idx])\n",
    "    axes[0, i].axis('off')\n",
    "    if i == 0:\n",
    "        axes[0, i].set_title('Cats', fontsize=12, weight='bold')\n",
    "\n",
    "for i, idx in enumerate(dog_indices):\n",
    "    axes[1, i].imshow(x_train_small[idx])\n",
    "    axes[1, i].axis('off')\n",
    "    if i == 0:\n",
    "        axes[1, i].set_title('Dogs', fontsize=12, weight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Note: CIFAR-10 images are 32x32 pixels, quite small!\")\n",
    "print(\"Pre-trained models expect 224x224, so we'll need to resize.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing for Pre-trained Models\n",
    "\n",
    "Pre-trained models expect specific input formats. We need to:\n",
    "1. Resize images to the expected input size (224x224 for most models)\n",
    "2. Apply model-specific preprocessing (e.g., normalization)\n",
    "3. Ensure proper data types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications.mobilenet_v2 import preprocess_input\n",
    "\n",
    "# Function to preprocess images for transfer learning\n",
    "def preprocess_images(images, target_size=(224, 224)):\n",
    "    \"\"\"\n",
    "    Resize and preprocess images for pre-trained models\n",
    "    \"\"\"\n",
    "    processed_images = []\n",
    "    for img in images:\n",
    "        # Resize using TensorFlow\n",
    "        img_resized = tf.image.resize(img, target_size)\n",
    "        processed_images.append(img_resized.numpy())\n",
    "    \n",
    "    processed_images = np.array(processed_images)\n",
    "    # Apply model-specific preprocessing\n",
    "    processed_images = preprocess_input(processed_images)\n",
    "    return processed_images\n",
    "\n",
    "print(\"Preprocessing images...\")\n",
    "x_train_processed = preprocess_images(x_train_small)\n",
    "x_test_processed = preprocess_images(x_test)\n",
    "\n",
    "print(f\"\\nPreprocessing complete:\")\n",
    "print(f\"  - New shape: {x_train_processed.shape}\")\n",
    "print(f\"  - Value range: [{x_train_processed.min():.2f}, {x_train_processed.max():.2f}]\")\n",
    "print(f\"  - Data type: {x_train_processed.dtype}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Approach 1: Feature Extraction\n",
    "\n",
    "In this approach, we freeze the pre-trained convolutional base and only train new classification layers. This is fast and works well with small datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a model using feature extraction\n",
    "print(\"Building feature extraction model...\\n\")\n",
    "\n",
    "# Use MobileNetV2 as the base\n",
    "base_model = MobileNetV2(weights='imagenet', \n",
    "                        include_top=False, \n",
    "                        input_shape=(224, 224, 3))\n",
    "\n",
    "# Freeze the base model\n",
    "base_model.trainable = False\n",
    "\n",
    "print(f\"Base model trainable: {base_model.trainable}\")\n",
    "print(f\"Number of trainable weights: {len(base_model.trainable_weights)}\")\n",
    "\n",
    "# Build the complete model\n",
    "model_fe = models.Sequential([\n",
    "    base_model,\n",
    "    layers.GlobalAveragePooling2D(),\n",
    "    layers.Dense(128, activation='relu'),\n",
    "    layers.Dropout(0.5),\n",
    "    layers.Dense(1, activation='sigmoid')\n",
    "], name='feature_extraction_model')\n",
    "\n",
    "# Compile the model\n",
    "model_fe.compile(\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=0.001),\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "print(\"\\nModel architecture:\")\n",
    "model_fe.summary()\n",
    "\n",
    "# Count trainable vs non-trainable parameters\n",
    "trainable_count = np.sum([keras.backend.count_params(w) for w in model_fe.trainable_weights])\n",
    "non_trainable_count = np.sum([keras.backend.count_params(w) for w in model_fe.non_trainable_weights])\n",
    "\n",
    "print(f\"\\nParameter breakdown:\")\n",
    "print(f\"  - Trainable parameters: {trainable_count:,}\")\n",
    "print(f\"  - Non-trainable parameters: {non_trainable_count:,}\")\n",
    "print(f\"  - Total parameters: {trainable_count + non_trainable_count:,}\")\n",
    "print(f\"  - Percentage trainable: {100 * trainable_count / (trainable_count + non_trainable_count):.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the feature extraction model\n",
    "print(\"Training feature extraction model...\\n\")\n",
    "\n",
    "history_fe = model_fe.fit(\n",
    "    x_train_processed, y_train_small,\n",
    "    batch_size=32,\n",
    "    epochs=10,\n",
    "    validation_split=0.2,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "print(\"\\nTraining complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Approach 2: Fine-Tuning\n",
    "\n",
    "In fine-tuning, we unfreeze some or all layers of the pre-trained model and continue training with a lower learning rate. This can achieve better performance but requires more careful tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a model for fine-tuning\n",
    "print(\"Building fine-tuning model...\\n\")\n",
    "\n",
    "# Create a new base model\n",
    "base_model_ft = MobileNetV2(weights='imagenet', \n",
    "                           include_top=False, \n",
    "                           input_shape=(224, 224, 3))\n",
    "\n",
    "# First, train with frozen base (same as feature extraction)\n",
    "base_model_ft.trainable = False\n",
    "\n",
    "# Build model\n",
    "model_ft = models.Sequential([\n",
    "    base_model_ft,\n",
    "    layers.GlobalAveragePooling2D(),\n",
    "    layers.Dense(128, activation='relu'),\n",
    "    layers.Dropout(0.5),\n",
    "    layers.Dense(1, activation='sigmoid')\n",
    "], name='fine_tuning_model')\n",
    "\n",
    "# Compile and train briefly with frozen base\n",
    "model_ft.compile(\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=0.001),\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "print(\"Phase 1: Training with frozen base...\")\n",
    "history_ft_phase1 = model_ft.fit(\n",
    "    x_train_processed, y_train_small,\n",
    "    batch_size=32,\n",
    "    epochs=5,\n",
    "    validation_split=0.2,\n",
    "    verbose=0\n",
    ")\n",
    "\n",
    "print(f\"Phase 1 complete. Final accuracy: {history_ft_phase1.history['accuracy'][-1]:.4f}\")\n",
    "\n",
    "# Now unfreeze the base model for fine-tuning\n",
    "print(\"\\nPhase 2: Unfreezing base model for fine-tuning...\")\n",
    "base_model_ft.trainable = True\n",
    "\n",
    "# Let's unfreeze only the last 20 layers\n",
    "# (fine-tuning only top layers is often more stable)\n",
    "for layer in base_model_ft.layers[:-20]:\n",
    "    layer.trainable = False\n",
    "\n",
    "print(f\"Layers in base model: {len(base_model_ft.layers)}\")\n",
    "print(f\"Trainable layers: {sum([1 for layer in base_model_ft.layers if layer.trainable])}\")\n",
    "\n",
    "# Recompile with a lower learning rate\n",
    "model_ft.compile(\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=0.0001),  # Lower learning rate!\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "print(\"\\nTraining with fine-tuning...\")\n",
    "history_ft_phase2 = model_ft.fit(\n",
    "    x_train_processed, y_train_small,\n",
    "    batch_size=32,\n",
    "    epochs=10,\n",
    "    validation_split=0.2,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "print(\"\\nFine-tuning complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparing Results\n",
    "\n",
    "Let's compare the performance of both approaches and visualize the training history."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate both models on test set\n",
    "print(\"Evaluating models on test set...\\n\")\n",
    "\n",
    "# Feature extraction model\n",
    "loss_fe, acc_fe = model_fe.evaluate(x_test_processed, y_test, verbose=0)\n",
    "print(f\"Feature Extraction Model:\")\n",
    "print(f\"  - Test Loss: {loss_fe:.4f}\")\n",
    "print(f\"  - Test Accuracy: {acc_fe:.4f}\")\n",
    "\n",
    "# Fine-tuning model\n",
    "loss_ft, acc_ft = model_ft.evaluate(x_test_processed, y_test, verbose=0)\n",
    "print(f\"\\nFine-Tuning Model:\")\n",
    "print(f\"  - Test Loss: {loss_ft:.4f}\")\n",
    "print(f\"  - Test Accuracy: {acc_ft:.4f}\")\n",
    "\n",
    "# Compare improvement\n",
    "improvement = (acc_ft - acc_fe) * 100\n",
    "print(f\"\\nImprovement from fine-tuning: {improvement:+.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize training history\n",
    "fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "# Plot accuracy\n",
    "axes[0].plot(history_fe.history['accuracy'], label='FE Train', linewidth=2)\n",
    "axes[0].plot(history_fe.history['val_accuracy'], label='FE Val', linewidth=2, linestyle='--')\n",
    "\n",
    "# For fine-tuning, combine both phases\n",
    "ft_train_acc = history_ft_phase1.history['accuracy'] + history_ft_phase2.history['accuracy']\n",
    "ft_val_acc = history_ft_phase1.history['val_accuracy'] + history_ft_phase2.history['val_accuracy']\n",
    "axes[0].plot(range(len(ft_train_acc)), ft_train_acc, label='FT Train', linewidth=2)\n",
    "axes[0].plot(range(len(ft_val_acc)), ft_val_acc, label='FT Val', linewidth=2, linestyle='--')\n",
    "axes[0].axvline(x=5, color='red', linestyle=':', label='Unfreeze', alpha=0.7)\n",
    "\n",
    "axes[0].set_xlabel('Epoch', fontsize=12)\n",
    "axes[0].set_ylabel('Accuracy', fontsize=12)\n",
    "axes[0].set_title('Model Accuracy Comparison', fontsize=14, weight='bold')\n",
    "axes[0].legend()\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Plot loss\n",
    "axes[1].plot(history_fe.history['loss'], label='FE Train', linewidth=2)\n",
    "axes[1].plot(history_fe.history['val_loss'], label='FE Val', linewidth=2, linestyle='--')\n",
    "\n",
    "ft_train_loss = history_ft_phase1.history['loss'] + history_ft_phase2.history['loss']\n",
    "ft_val_loss = history_ft_phase1.history['val_loss'] + history_ft_phase2.history['val_loss']\n",
    "axes[1].plot(range(len(ft_train_loss)), ft_train_loss, label='FT Train', linewidth=2)\n",
    "axes[1].plot(range(len(ft_val_loss)), ft_val_loss, label='FT Val', linewidth=2, linestyle='--')\n",
    "axes[1].axvline(x=5, color='red', linestyle=':', label='Unfreeze', alpha=0.7)\n",
    "\n",
    "axes[1].set_xlabel('Epoch', fontsize=12)\n",
    "axes[1].set_ylabel('Loss', fontsize=12)\n",
    "axes[1].set_title('Model Loss Comparison', fontsize=14, weight='bold')\n",
    "axes[1].legend()\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('training_comparison.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nKey Observations:\")\n",
    "print(\"1. Feature extraction converges quickly (few parameters to train)\")\n",
    "print(\"2. Fine-tuning shows gradual improvement after unfreezing\")\n",
    "print(\"3. The vertical red line shows when we unfroze layers for fine-tuning\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Detailed Performance Analysis\n",
    "\n",
    "Let's create a more detailed analysis of model performance including confusion matrices and classification reports."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions\n",
    "y_pred_fe = (model_fe.predict(x_test_processed, verbose=0) > 0.5).astype(int)\n",
    "y_pred_ft = (model_ft.predict(x_test_processed, verbose=0) > 0.5).astype(int)\n",
    "\n",
    "# Create confusion matrices\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Feature extraction confusion matrix\n",
    "cm_fe = confusion_matrix(y_test, y_pred_fe)\n",
    "sns.heatmap(cm_fe, annot=True, fmt='d', cmap='Blues', ax=axes[0],\n",
    "           xticklabels=['Cat', 'Dog'], yticklabels=['Cat', 'Dog'])\n",
    "axes[0].set_title('Feature Extraction\\nConfusion Matrix', fontsize=12, weight='bold')\n",
    "axes[0].set_ylabel('True Label', fontsize=11)\n",
    "axes[0].set_xlabel('Predicted Label', fontsize=11)\n",
    "\n",
    "# Fine-tuning confusion matrix\n",
    "cm_ft = confusion_matrix(y_test, y_pred_ft)\n",
    "sns.heatmap(cm_ft, annot=True, fmt='d', cmap='Greens', ax=axes[1],\n",
    "           xticklabels=['Cat', 'Dog'], yticklabels=['Cat', 'Dog'])\n",
    "axes[1].set_title('Fine-Tuning\\nConfusion Matrix', fontsize=12, weight='bold')\n",
    "axes[1].set_ylabel('True Label', fontsize=11)\n",
    "axes[1].set_xlabel('Predicted Label', fontsize=11)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('confusion_matrices.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# Print classification reports\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Feature Extraction Model - Classification Report\")\n",
    "print(\"=\"*60)\n",
    "print(classification_report(y_test, y_pred_fe, target_names=['Cat', 'Dog']))\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Fine-Tuning Model - Classification Report\")\n",
    "print(\"=\"*60)\n",
    "print(classification_report(y_test, y_pred_ft, target_names=['Cat', 'Dog']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing Predictions\n",
    "\n",
    "Let's visualize some predictions from our fine-tuned model to see where it succeeds and where it fails."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get predictions with probabilities\n",
    "y_pred_proba = model_ft.predict(x_test_processed, verbose=0).flatten()\n",
    "\n",
    "# Find some interesting cases\n",
    "correct_mask = (y_pred_ft.flatten() == y_test.flatten())\n",
    "incorrect_indices = np.where(~correct_mask)[0]\n",
    "correct_confident_indices = np.where(correct_mask & (np.abs(y_pred_proba - 0.5) > 0.4))[0]\n",
    "\n",
    "# Visualize\n",
    "fig, axes = plt.subplots(3, 8, figsize=(16, 6))\n",
    "fig.suptitle('Model Predictions Analysis', fontsize=14, weight='bold')\n",
    "\n",
    "# Row 1: Correct and confident predictions\n",
    "for i in range(8):\n",
    "    if i < len(correct_confident_indices):\n",
    "        idx = correct_confident_indices[i]\n",
    "        # Get original image (before preprocessing)\n",
    "        orig_img_idx = np.where((x_test == x_test[idx]).all(axis=(1,2,3)))[0][0] if len(x_test) > idx else idx\n",
    "        axes[0, i].imshow(x_test[orig_img_idx])\n",
    "        true_label = 'Dog' if y_test[idx] == 1 else 'Cat'\n",
    "        conf = y_pred_proba[idx] if y_test[idx] == 1 else 1 - y_pred_proba[idx]\n",
    "        axes[0, i].set_title(f'{true_label}\\n{conf:.2%}', fontsize=9, color='green', weight='bold')\n",
    "    axes[0, i].axis('off')\n",
    "if len(correct_confident_indices) > 0:\n",
    "    axes[0, 0].text(-0.3, 0.5, 'Correct\\n(Confident)', transform=axes[0, 0].transAxes,\n",
    "                   fontsize=11, weight='bold', va='center', rotation=90)\n",
    "\n",
    "# Row 2: Correct but uncertain predictions\n",
    "uncertain_correct = np.where(correct_mask & (np.abs(y_pred_proba - 0.5) < 0.2))[0]\n",
    "for i in range(8):\n",
    "    if i < len(uncertain_correct):\n",
    "        idx = uncertain_correct[i]\n",
    "        axes[1, i].imshow(x_test[idx])\n",
    "        true_label = 'Dog' if y_test[idx] == 1 else 'Cat'\n",
    "        conf = y_pred_proba[idx] if y_test[idx] == 1 else 1 - y_pred_proba[idx]\n",
    "        axes[1, i].set_title(f'{true_label}\\n{conf:.2%}', fontsize=9, color='orange', weight='bold')\n",
    "    axes[1, i].axis('off')\n",
    "if len(uncertain_correct) > 0:\n",
    "    axes[1, 0].text(-0.3, 0.5, 'Correct\\n(Uncertain)', transform=axes[1, 0].transAxes,\n",
    "                   fontsize=11, weight='bold', va='center', rotation=90)\n",
    "\n",
    "# Row 3: Incorrect predictions\n",
    "for i in range(min(8, len(incorrect_indices))):\n",
    "    idx = incorrect_indices[i]\n",
    "    axes[2, i].imshow(x_test[idx])\n",
    "    true_label = 'Dog' if y_test[idx] == 1 else 'Cat'\n",
    "    pred_label = 'Dog' if y_pred_ft[idx] == 1 else 'Cat'\n",
    "    conf = y_pred_proba[idx] if y_pred_ft[idx] == 1 else 1 - y_pred_proba[idx]\n",
    "    axes[2, i].set_title(f'True: {true_label}\\nPred: {pred_label} ({conf:.2%})', \n",
    "                        fontsize=8, color='red', weight='bold')\n",
    "    axes[2, i].axis('off')\n",
    "for i in range(len(incorrect_indices), 8):\n",
    "    axes[2, i].axis('off')\n",
    "if len(incorrect_indices) > 0:\n",
    "    axes[2, 0].text(-0.3, 0.5, 'Incorrect', transform=axes[2, 0].transAxes,\n",
    "                   fontsize=11, weight='bold', va='center', rotation=90)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('prediction_analysis.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nPrediction Summary:\")\n",
    "print(f\"  - Total test samples: {len(y_test)}\")\n",
    "print(f\"  - Correct predictions: {np.sum(correct_mask)} ({100*np.sum(correct_mask)/len(y_test):.1f}%)\")\n",
    "print(f\"  - Incorrect predictions: {len(incorrect_indices)} ({100*len(incorrect_indices)/len(y_test):.1f}%)\")\n",
    "print(f\"  - High confidence (>90%): {np.sum(np.abs(y_pred_proba - 0.5) > 0.4)} samples\")\n",
    "print(f\"  - Low confidence (<60%): {np.sum(np.abs(y_pred_proba - 0.5) < 0.1)} samples\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Best Practices for Transfer Learning\n",
    "\n",
    "Based on our experiments and theoretical understanding, here are key best practices:\n",
    "\n",
    "### 1. **Choosing a Pre-trained Model**\n",
    "\n",
    "- **Task similarity**: Choose models trained on similar domains (e.g., ImageNet for general vision tasks)\n",
    "- **Model size**: Balance between performance and computational constraints\n",
    "- **Architecture**: Consider modern architectures (ResNet, EfficientNet, Vision Transformers)\n",
    "\n",
    "### 2. **Data Preprocessing**\n",
    "\n",
    "- Use the **same preprocessing** as the original model training\n",
    "- Pay attention to normalization schemes (some models use different ranges)\n",
    "- Consider **data augmentation** to improve generalization\n",
    "\n",
    "### 3. **Training Strategy**\n",
    "\n",
    "**For small datasets (< 10,000 samples)**:\n",
    "$$\\text{Strategy: Feature Extraction}$$\n",
    "- Freeze all pre-trained layers\n",
    "- Train only new classifier layers\n",
    "- Use standard learning rate (0.001)\n",
    "\n",
    "**For medium datasets (10,000 - 100,000 samples)**:\n",
    "$$\\text{Strategy: Partial Fine-tuning}$$\n",
    "- Freeze early layers\n",
    "- Fine-tune top layers\n",
    "- Use lower learning rate (0.0001)\n",
    "\n",
    "**For large datasets (> 100,000 samples)**:\n",
    "$$\\text{Strategy: Full Fine-tuning}$$\n",
    "- Fine-tune all layers\n",
    "- Use very low learning rate (0.00001)\n",
    "- May even consider training from scratch\n",
    "\n",
    "### 4. **Learning Rate Selection**\n",
    "\n",
    "Critical guideline for fine-tuning:\n",
    "\n",
    "$$\\alpha_{fine-tune} = \\frac{\\alpha_{scratch}}{10} \\text{ to } \\frac{\\alpha_{scratch}}{100}$$\n",
    "\n",
    "Use lower learning rates to avoid destroying pre-trained features.\n",
    "\n",
    "### 5. **Regularization**\n",
    "\n",
    "- Use **dropout** in new layers (0.3-0.5)\n",
    "- Apply **L2 regularization** if overfitting occurs\n",
    "- Consider **early stopping** based on validation loss\n",
    "- Use **data augmentation** when possible\n",
    "\n",
    "### 6. **Monitoring Training**\n",
    "\n",
    "Watch for these signs:\n",
    "- **Underfitting**: Both train and val accuracy are low â†’ Unfreeze more layers or increase capacity\n",
    "- **Overfitting**: Train accuracy high but val accuracy low â†’ Add regularization, reduce capacity, or get more data\n",
    "- **Good fit**: Both accuracies high and close together â†’ Model is working well!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hands-On Exercise: Build Your Own Transfer Learning Model\n",
    "\n",
    "Now it's your turn! Try building a transfer learning model with different configurations.\n",
    "\n",
    "### Exercise Tasks:\n",
    "\n",
    "1. **Try a different pre-trained model**: Use VGG16 or ResNet50 instead of MobileNetV2\n",
    "2. **Experiment with architecture**: Add more dense layers or change dropout rates\n",
    "3. **Adjust fine-tuning strategy**: Try unfreezing different numbers of layers\n",
    "4. **Data augmentation**: Implement data augmentation to improve performance\n",
    "5. **Multi-class classification**: Extend to classify all 10 CIFAR-10 classes instead of just cats vs dogs\n",
    "\n",
    "Here's a template to get you started:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise Template: Build your own transfer learning model\n",
    "\n",
    "# TODO: Choose a different base model\n",
    "# Options: VGG16, ResNet50, InceptionV3, EfficientNetB0\n",
    "base_model_exercise = VGG16(  # Try changing this!\n",
    "    weights='imagenet',\n",
    "    include_top=False,\n",
    "    input_shape=(224, 224, 3)\n",
    ")\n",
    "\n",
    "# TODO: Decide which layers to freeze\n",
    "# Experiment with:\n",
    "# - Freezing all layers: base_model_exercise.trainable = False\n",
    "# - Freezing only bottom layers: for layer in base_model_exercise.layers[:X]: layer.trainable = False\n",
    "# - No freezing: base_model_exercise.trainable = True\n",
    "\n",
    "base_model_exercise.trainable = False  # Start here, then experiment!\n",
    "\n",
    "# TODO: Design your classifier architecture\n",
    "model_exercise = models.Sequential([\n",
    "    base_model_exercise,\n",
    "    layers.GlobalAveragePooling2D(),\n",
    "    \n",
    "    # Add your layers here!\n",
    "    # Ideas:\n",
    "    # - layers.Dense(256, activation='relu')\n",
    "    # - layers.BatchNormalization()\n",
    "    # - layers.Dropout(0.5)\n",
    "    # - layers.Dense(128, activation='relu')\n",
    "    \n",
    "    layers.Dense(1, activation='sigmoid')  # For binary classification\n",
    "], name='my_transfer_learning_model')\n",
    "\n",
    "# TODO: Choose optimizer and learning rate\n",
    "model_exercise.compile(\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=0.001),  # Experiment with this!\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "print(\"\\nYour model:\")\n",
    "model_exercise.summary()\n",
    "\n",
    "# TODO: Train your model\n",
    "# Experiment with:\n",
    "# - Different batch sizes\n",
    "# - Different number of epochs\n",
    "# - Data augmentation (use ImageDataGenerator)\n",
    "\n",
    "print(\"\\nReady to train! Uncomment the following lines to start training:\")\n",
    "print(\"\"\"\\n# history_exercise = model_exercise.fit(\n",
    "#     x_train_processed, y_train_small,\n",
    "#     batch_size=32,\n",
    "#     epochs=10,\n",
    "#     validation_split=0.2,\n",
    "#     verbose=1\n",
    "# )\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Advanced: Data Augmentation for Better Performance\n",
    "\n",
    "Data augmentation is a powerful technique to improve model generalization, especially important when working with limited data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create data augmentation pipeline\n",
    "data_augmentation = keras.Sequential([\n",
    "    layers.RandomFlip(\"horizontal\"),\n",
    "    layers.RandomRotation(0.1),\n",
    "    layers.RandomZoom(0.1),\n",
    "    layers.RandomContrast(0.1),\n",
    "], name='data_augmentation')\n",
    "\n",
    "# Visualize augmentation effects\n",
    "sample_image = x_train_processed[0:1]\n",
    "\n",
    "fig, axes = plt.subplots(2, 4, figsize=(12, 6))\n",
    "fig.suptitle('Data Augmentation Examples', fontsize=14, weight='bold')\n",
    "\n",
    "for i in range(8):\n",
    "    ax = axes[i // 4, i % 4]\n",
    "    augmented = data_augmentation(sample_image, training=True)\n",
    "    # Denormalize for visualization\n",
    "    img_display = augmented[0].numpy()\n",
    "    img_display = (img_display - img_display.min()) / (img_display.max() - img_display.min())\n",
    "    ax.imshow(img_display)\n",
    "    ax.axis('off')\n",
    "    ax.set_title(f'Augmentation {i+1}', fontsize=10)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('data_augmentation.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nData augmentation techniques applied:\")\n",
    "print(\"  - Random horizontal flips\")\n",
    "print(\"  - Random rotations (Â±10%)\")\n",
    "print(\"  - Random zoom (Â±10%)\")\n",
    "print(\"  - Random contrast adjustments (Â±10%)\")\n",
    "print(\"\\nThese help the model learn more robust features!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Key Takeaways\n",
    "\n",
    "Congratulations on completing this comprehensive lesson on transfer learning! Here are the key points to remember:\n",
    "\n",
    "### Core Concepts\n",
    "\n",
    "1. **Transfer Learning Fundamentals**:\n",
    "   - Reuses knowledge from pre-trained models trained on large datasets\n",
    "   - Particularly powerful when you have limited training data\n",
    "   - Based on the idea that features learned for one task can be useful for related tasks\n",
    "\n",
    "2. **Two Main Approaches**:\n",
    "   - **Feature Extraction**: Freeze pre-trained layers, train only new classifier (fast, safe for small data)\n",
    "   - **Fine-Tuning**: Continue training pre-trained layers with low learning rate (better performance, needs more data)\n",
    "\n",
    "3. **When to Use What**:\n",
    "   - Small dataset + similar task â†’ Feature extraction\n",
    "   - Small dataset + different task â†’ Feature extraction with more new layers\n",
    "   - Large dataset + similar task â†’ Fine-tuning\n",
    "   - Large dataset + different task â†’ Fine-tuning or training from scratch\n",
    "\n",
    "### Practical Skills Gained\n",
    "\n",
    "- Loading and using pre-trained models from Keras/TensorFlow\n",
    "- Freezing and unfreezing layers for different training strategies\n",
    "- Properly preprocessing data for pre-trained models\n",
    "- Implementing both feature extraction and fine-tuning approaches\n",
    "- Evaluating and comparing model performance\n",
    "- Understanding the trade-offs between different approaches\n",
    "\n",
    "### Mathematical Insights\n",
    "\n",
    "- Pre-trained models learn hierarchical features from simple to complex\n",
    "- Fine-tuning requires much lower learning rates than training from scratch\n",
    "- The choice of how many layers to freeze depends on data size and task similarity\n",
    "\n",
    "### Best Practices\n",
    "\n",
    "- Always use the same preprocessing as the original pre-trained model\n",
    "- Start with frozen base and new classifier, then fine-tune if needed\n",
    "- Use learning rates 10-100x lower for fine-tuning\n",
    "- Monitor both training and validation metrics to detect overfitting\n",
    "- Consider data augmentation to improve generalization\n",
    "- Choose models based on task requirements and computational constraints"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Further Resources\n",
    "\n",
    "To deepen your understanding of transfer learning and continue your journey in deep learning:\n",
    "\n",
    "### Essential Reading\n",
    "\n",
    "1. **Research Papers**:\n",
    "   - [\"A Survey on Transfer Learning\"](https://www.cse.ust.hk/~qyang/Docs/2009/tkde_transfer_learning.pdf) by Pan & Yang (2010) - Comprehensive overview\n",
    "   - [\"Deep Residual Learning for Image Recognition\"](https://arxiv.org/abs/1512.03385) - The ResNet paper\n",
    "   - [\"Very Deep Convolutional Networks for Large-Scale Image Recognition\"](https://arxiv.org/abs/1409.1556) - The VGG paper\n",
    "   - [\"Rethinking the Inception Architecture\"](https://arxiv.org/abs/1512.00567) - Inception v3 and transfer learning insights\n",
    "\n",
    "2. **Official Documentation**:\n",
    "   - [TensorFlow Transfer Learning Guide](https://www.tensorflow.org/tutorials/images/transfer_learning)\n",
    "   - [Keras Applications Documentation](https://keras.io/api/applications/)\n",
    "   - [PyTorch Transfer Learning Tutorial](https://pytorch.org/tutorials/beginner/transfer_learning_tutorial.html)\n",
    "\n",
    "3. **Books**:\n",
    "   - \"Deep Learning with Python\" by FranÃ§ois Chollet (creator of Keras)\n",
    "   - \"Hands-On Machine Learning with Scikit-Learn, Keras, and TensorFlow\" by AurÃ©lien GÃ©ron\n",
    "   - \"Deep Learning\" by Goodfellow, Bengio, and Courville (free online)\n",
    "\n",
    "### Online Courses and Tutorials\n",
    "\n",
    "4. **Video Tutorials**:\n",
    "   - [Stanford CS231n: Convolutional Neural Networks for Visual Recognition](http://cs231n.stanford.edu/)\n",
    "   - [Fast.ai Practical Deep Learning for Coders](https://course.fast.ai/)\n",
    "   - [DeepLearning.AI TensorFlow Developer Specialization](https://www.coursera.org/professional-certificates/tensorflow-in-practice)\n",
    "\n",
    "5. **Interactive Resources**:\n",
    "   - [TensorFlow Hub](https://tfhub.dev/) - Repository of pre-trained models\n",
    "   - [Hugging Face Model Hub](https://huggingface.co/models) - Pre-trained models for NLP and vision\n",
    "   - [Papers with Code](https://paperswithcode.com/methods/category/transfer-learning) - Latest research with implementations\n",
    "\n",
    "### Practical Applications\n",
    "\n",
    "6. **Datasets for Practice**:\n",
    "   - [Kaggle Datasets](https://www.kaggle.com/datasets) - Real-world datasets\n",
    "   - [TensorFlow Datasets](https://www.tensorflow.org/datasets) - Ready-to-use datasets\n",
    "   - [ImageNet](https://www.image-net.org/) - The dataset most pre-trained models are trained on\n",
    "\n",
    "7. **Model Zoos and Pre-trained Models**:\n",
    "   - [TensorFlow Model Garden](https://github.com/tensorflow/models)\n",
    "   - [ONNX Model Zoo](https://github.com/onnx/models)\n",
    "   - [Timm (PyTorch Image Models)](https://github.com/rwightman/pytorch-image-models)\n",
    "\n",
    "### Community and Discussion\n",
    "\n",
    "8. **Forums and Communities**:\n",
    "   - [r/MachineLearning](https://www.reddit.com/r/MachineLearning/) - Reddit community\n",
    "   - [Stack Overflow](https://stackoverflow.com/questions/tagged/transfer-learning) - Q&A\n",
    "   - [Cross Validated](https://stats.stackexchange.com/) - Statistical ML discussions\n",
    "\n",
    "### Next Steps in Your Learning Journey\n",
    "\n",
    "- Experiment with different pre-trained models on your own datasets\n",
    "- Explore transfer learning in other domains (NLP, audio, time series)\n",
    "- Learn about advanced techniques like multi-task learning and meta-learning\n",
    "- Study domain adaptation for when source and target domains differ significantly\n",
    "- Investigate how to create your own pre-trained models for specific domains"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "Transfer learning has revolutionized how we approach machine learning problems, making state-of-the-art performance accessible even with limited data and computational resources. By leveraging pre-trained models, you can build powerful applications without training from scratch.\n",
    "\n",
    "Remember: the key to successful transfer learning is understanding your data, choosing the right strategy, and carefully monitoring your model's performance. Don't be afraid to experiment with different approaches!\n",
    "\n",
    "**Happy learning, and good luck with your transfer learning projects!** ðŸš€"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
