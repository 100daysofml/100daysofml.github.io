

<!DOCTYPE html>


<html lang="en" data-content_root="" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.18.1: http://docutils.sourceforge.net/" />

    <title>Introduction to Naive Bayes Classifier &#8212; 100 Days of Machine Learning</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "light";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../_static/styles/theme.css?digest=5b4479735964841361fd" rel="stylesheet" />
<link href="../_static/styles/bootstrap.css?digest=5b4479735964841361fd" rel="stylesheet" />
<link href="../_static/styles/pydata-sphinx-theme.css?digest=5b4479735964841361fd" rel="stylesheet" />

  
  <link href="../_static/vendor/fontawesome/6.1.2/css/all.min.css?digest=5b4479735964841361fd" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.1.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.1.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.1.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="../_static/pygments.css" />
    <link rel="stylesheet" href="../_static/styles/sphinx-book-theme.css?digest=14f4ca6b54d191a8c7657f6c759bf11a5fb86285" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../_static/design-style.4045f2051d55cab465a707391d5b2007.min.css" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../_static/scripts/bootstrap.js?digest=5b4479735964841361fd" />
<link rel="preload" as="script" href="../_static/scripts/pydata-sphinx-theme.js?digest=5b4479735964841361fd" />
  <script src="../_static/vendor/fontawesome/6.1.2/js/all.min.js?digest=5b4479735964841361fd"></script>

    <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/_sphinx_javascript_frameworks_compat.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/clipboard.min.js"></script>
    <script src="../_static/copybutton.js"></script>
    <script src="../_static/scripts/sphinx-book-theme.js?digest=5a5c038af52cf7bc1a1ec88eea08e6366ee68824"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../_static/togglebutton.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="../_static/design-tabs.js"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"
const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
    <script async="async" src="../_static/sphinx-thebe.js"></script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'Week_06/Lesson_30';</script>
    <link rel="canonical" href="https://100daysofml.com/Week_06/Lesson_30.html" />
    <link rel="shortcut icon" href="../_static/100days.ico"/>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Course Structure" href="../Week_07/007_Overview.html" />
    <link rel="prev" title="Day 29: Introduction to Decision Trees" href="Lesson_29.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <a class="skip-link" href="#main-content">Skip to main content</a>
  
  <div id="pst-scroll-pixel-helper"></div>

  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>
    Back to top
  </button>

  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__primary"
          id="__primary"/>
  <label class="overlay overlay-primary" for="__primary"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__secondary"
          id="__secondary"/>
  <label class="overlay overlay-secondary" for="__secondary"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search this book..."
         aria-label="Search this book..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>
  
    <nav class="bd-header navbar navbar-expand-lg bd-navbar">
    </nav>
  
  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">

  

<a class="navbar-brand logo" href="../index.html">
  
  
  
  
  
    
    
      
    
    
    <img src="../_static/100days_circle.jpg" class="logo__image only-light" alt="100 Days of Machine Learning - Home"/>
    <script>document.write(`<img src="../_static/100days_circle.jpg" class="logo__image only-dark" alt="100 Days of Machine Learning - Home"/>`);</script>
  
  
</a></div>
        <div class="sidebar-primary-item"><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="../index.html">
                    100 Days of Machine Learning Challenge
                </a>
            </li>
        </ul>
        <p aria-level="2" class="caption" role="heading"><span class="caption-text">Preface</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="../Week_00/00_Overview.html">Welcome: Overview</a><input class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-1"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../Week_00/00a_DailyChallenge.html">Daily Challenge Curriculum</a></li>

<li class="toctree-l2"><a class="reference internal" href="../Week_00/00b_DailyResources.html"><strong>Daily Curriculum Resources</strong></a></li>






















<li class="toctree-l2"><a class="reference internal" href="../Week_00/01_Errata.html">Errata: Corrections History</a></li>
</ul>
</li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Week 1 - Introduction to Python Basics</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="../Week_01/001_Overview.html">Week_01: Overview</a><input class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-2"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../Week_01/Lesson_01.html">Day 1 - Python Basics</a></li>
<li class="toctree-l2"><a class="reference internal" href="../Week_01/Lesson_02.html">Day 2 - Python Data</a></li>
<li class="toctree-l2"><a class="reference internal" href="../Week_01/Lesson_03.html">Day 3 - Control Structures in Python: Loops</a></li>
<li class="toctree-l2"><a class="reference internal" href="../Week_01/Lesson_04.html">Day 4 - Control Structures in Python: Conditional Statements</a></li>
<li class="toctree-l2"><a class="reference internal" href="../Week_01/Lesson_05.html">Day 5 - Functions and Modules</a></li>
</ul>
</li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Week 2 - Introduction to Machine Learning Mathematics</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="../Week_02/002_Overview.html">Week_02: Overview</a><input class="toctree-checkbox" id="toctree-checkbox-3" name="toctree-checkbox-3" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-3"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../Week_02/Lesson_06.html">Day 6 - Linear Algebra - Vectors</a></li>
<li class="toctree-l2"><a class="reference internal" href="../Week_02/Lesson_07.html">Day 7 - Linear Algebra - Matrices and Matrix Operations</a></li>
<li class="toctree-l2"><a class="reference internal" href="../Week_02/Lesson_08.html">Day 8 - Calculus - Derivatives, Concept and Application</a></li>
<li class="toctree-l2"><a class="reference internal" href="../Week_02/Lesson_09.html">Day 9 - Calculus - Integrals, Fundamental Theorems</a></li>
<li class="toctree-l2"><a class="reference internal" href="../Week_02/Lesson_10.html">Day 10 - Statistics and Probability - Concepts and Relevant Distributions</a></li>
</ul>
</li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Week 3 - Data Preprocessing</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="../Week_03/003_Overview.html">Week_03: Overview</a><input class="toctree-checkbox" id="toctree-checkbox-4" name="toctree-checkbox-4" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-4"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../Week_03/Lesson_11.html">Day 11 - Introduction to Data Preprocessing</a></li>
<li class="toctree-l2"><a class="reference internal" href="../Week_03/Lesson_12.html">Day 12: In-Depth Exploration of Data Splitting Techniques in Python with Cross-Validation</a></li>

<li class="toctree-l2"><a class="reference internal" href="../Week_03/Lesson_12solution.html">Day 12: In-Depth Exploration of Data Splitting Techniques - Solution</a></li>

<li class="toctree-l2"><a class="reference internal" href="../Week_03/Lesson_13.html">Day 13 - Handling Missing Data in Python</a></li>
<li class="toctree-l2"><a class="reference internal" href="../Week_03/Lesson_14.html">Day 14 - Data Normalization and Scaling using Python</a></li>
<li class="toctree-l2"><a class="reference internal" href="../Week_03/Lesson_15.html">Day 15: Encoding Categorical Data in Python - Expanded with Mathematical Implications</a></li>

</ul>
</li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Week 4 - Data Preprocessing</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="../Week_04/004_Overview.html">Week_04: Overview</a><input class="toctree-checkbox" id="toctree-checkbox-5" name="toctree-checkbox-5" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-5"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../Week_04/Lesson_16.html">Day 16 - Introduction to EDA and Data Visualization in Python</a></li>
<li class="toctree-l2"><a class="reference internal" href="../Week_04/Lesson_17.html">Day 17 - Implementing Descriptive Statistics for EDA in Python</a></li>
<li class="toctree-l2"><a class="reference internal" href="../Week_04/Lesson_18.html">Day 18 - Visualization Techniques for Data Distribution in Python</a></li>
<li class="toctree-l2"><a class="reference internal" href="../Week_04/Lesson_19.html">Day 19: Correlation Analysis using Python</a></li>

<li class="toctree-l2"><a class="reference internal" href="../Week_04/Lesson_20.html">Day 20: Advanced Feature Selection and Importance in Python - With Iris Dataset</a></li>


</ul>
</li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Week 5: Supervised Learning - Regression</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="../Week_05/005_Overview.html">Week_05: Overview</a><input class="toctree-checkbox" id="toctree-checkbox-6" name="toctree-checkbox-6" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-6"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../Week_05/Lesson_21.html">Day 21 - Introduction to Regression Analysis in Python</a></li>
<li class="toctree-l2"><a class="reference internal" href="../Week_05/Lesson_22.html">Day 22: Implementing Multiple Linear Regression in Python</a></li>

<li class="toctree-l2"><a class="reference internal" href="../Week_05/Lesson_23.html">Day 23 - Advanced Regression Techniques - Polynomial, Lasso, and Ridge Regression</a></li>
<li class="toctree-l2"><a class="reference internal" href="../Week_05/Lesson_24.html">Day 24 - Regression Model Evaluation Metrics in Python</a></li>
<li class="toctree-l2"><a class="reference internal" href="../Week_05/Lesson_25.html">Day 25 - Addressing Overfitting and Underfitting in Regression Models</a></li>
</ul>
</li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Week 6: Supervised Learning - Classification</span></p>
<ul class="current nav bd-sidenav">
<li class="toctree-l1 current active has-children"><a class="reference internal" href="006_Overview.html">Week_06: Overview</a><input checked="" class="toctree-checkbox" id="toctree-checkbox-7" name="toctree-checkbox-7" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-7"><i class="fa-solid fa-chevron-down"></i></label><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="Lesson_26.html">Day 26: Introduction to Classification and Logistic Regression in Python</a></li>


<li class="toctree-l2"><a class="reference internal" href="Lesson_27.html">Day 27: Introduction to the K-Nearest Neighbors (K-NN) Algorithm</a></li>



<li class="toctree-l2"><a class="reference internal" href="Lesson_28.html">Day 28: Introduction to Support Vector Machines (SVM)</a></li>



<li class="toctree-l2"><a class="reference internal" href="Lesson_29.html">Day 29: Introduction to Decision Trees</a></li>


<li class="toctree-l2 current active"><a class="current reference internal" href="#">Introduction to Naive Bayes Classifier</a></li>


</ul>
</li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Week 7: Ensemble Methods</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="../Week_07/007_Overview.html">Week_07: Overview</a><input class="toctree-checkbox" id="toctree-checkbox-8" name="toctree-checkbox-8" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-8"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../Week_07/Lesson_31.html">Day 31: Introduction to Ensemble Learning Techniques</a></li>


<li class="toctree-l2"><a class="reference internal" href="../Week_07/Lesson_32.html">Day 32: Introduction to Bagging and Random Forests</a></li>



<li class="toctree-l2"><a class="reference internal" href="../Week_07/Lesson_33.html">Day 33: Introduction to AdaBoost</a></li>



<li class="toctree-l2"><a class="reference internal" href="../Week_07/Lesson_34.html">Day 34: Introduction to Gradient Boosting Machines (GBM) and Extreme Gradient Boosting (XGBoost)</a></li>



</ul>
</li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><label class="sidebar-toggle primary-toggle btn btn-sm" for="__primary" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</label></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-launch-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Launch interactive content">
    <i class="fas fa-rocket"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://notebooks.gesis.org/binder/jupyter/user/100daysofml-100-sofml.github.io-4iw5ztbi/lab/workspaces/auto-e/v2/gh/100daysofml/100daysofml.github.io/master?urlpath=tree/Week_06/Lesson_30.ipynb" target="_blank"
   class="btn btn-sm dropdown-item"
   title="Launch onBinder"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  
    <img src="../_static/images/logo_binder.svg">
  </span>
<span class="btn__text-container">Binder</span>
</a>
</li>
      
      
      
      
      <li><a href="https://colab.research.google.com/github/100daysofml/100daysofml.github.io/github/100daysofml/100daysofml.github.io/blob/master/Week_06/Lesson_30.ipynb" target="_blank"
   class="btn btn-sm dropdown-item"
   title="Launch onColab"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  
    <img src="../_static/images/logo_colab.png">
  </span>
<span class="btn__text-container">Colab</span>
</a>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-source-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Source repositories">
    <i class="fab fa-github"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://github.com/100daysofml/100daysofml.github.io" target="_blank"
   class="btn btn-sm btn-source-repository-button dropdown-item"
   title="Source repository"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="btn__text-container">Repository</span>
</a>
</li>
      
      
      
      
      <li><a href="https://github.com/100daysofml/100daysofml.github.io/edit/master/Week_06/Lesson_30.ipynb" target="_blank"
   class="btn btn-sm btn-source-edit-button dropdown-item"
   title="Suggest edit"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-pencil-alt"></i>
  </span>
<span class="btn__text-container">Suggest edit</span>
</a>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="../_sources/Week_06/Lesson_30.ipynb" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.ipynb</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>



<script>
document.write(`
  <button class="btn btn-sm navbar-btn theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="theme-switch nav-link" data-mode="light"><i class="fa-solid fa-sun fa-lg"></i></span>
    <span class="theme-switch nav-link" data-mode="dark"><i class="fa-solid fa-moon fa-lg"></i></span>
    <span class="theme-switch nav-link" data-mode="auto"><i class="fa-solid fa-circle-half-stroke fa-lg"></i></span>
  </button>
`);
</script>


<script>
document.write(`
  <button class="btn btn-sm navbar-btn search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
  </button>
`);
</script>
<label class="sidebar-toggle secondary-toggle btn btn-sm" for="__secondary"title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</label>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>Introduction to Naive Bayes Classifier</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#">Introduction to Naive Bayes Classifier</a><ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#understanding-bayes-theorem-and-conditional-probability">Understanding Bayes’ Theorem and Conditional Probability</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#conditional-probability">Conditional Probability</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#interpretation">Interpretation</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#cat-size-vs-color">Cat Size vs Color</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#applications-and-examples">Applications and Examples</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#develop-an-intuition-for-conditional-probability">Develop An Intuition For Conditional Probability</a></li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#on-synthetic-data">On Synthetic Data</a></li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#constructing-a-naive-bayes-classifier-with-pomegranate">Constructing a Naive Bayes Classifier with pomegranate</a><ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#exercise-for-the-reader">Exercise For The Reader</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#definition">Definition</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#task-workflow">Task Workflow:</a></li>
</ul>
</li>
</ul>
</li>
</ul>

            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article" role="main">
                  
  <section class="tex2jax_ignore mathjax_ignore" id="introduction-to-naive-bayes-classifier">
<h1>Introduction to Naive Bayes Classifier<a class="headerlink" href="#introduction-to-naive-bayes-classifier" title="Permalink to this heading">#</a></h1>
<p>The Naive Bayes Classifier stands as a cornerstone in the field of machine learning, offering a simplistic yet powerful approach to solving classification problems. By leveraging the principles of probability, this model aids in predicting the category of a given sample based on its attributes. Its name stems from the naïve assumption that all features are independent of each other, an assumption that simplifies calculations without significantly compromising performance in many cases. This lesson embarks on a journey to unravel the mechanics behind the Naive Bayes Classifier, including its theoretical foundations and practical applications, illustrating its significant role in the analytics and data science arena.</p>
<section id="understanding-bayes-theorem-and-conditional-probability">
<h2>Understanding Bayes’ Theorem and Conditional Probability<a class="headerlink" href="#understanding-bayes-theorem-and-conditional-probability" title="Permalink to this heading">#</a></h2>
<p>Bayes’ Theorem is a fundamental theorem in probability theory and statistics, offering a framework for understanding how the probability of a theory or hypothesis, A, changes in light of new evidence, B. The theorem is mathematically expressed as:</p>
<div class="math notranslate nohighlight">
\[
P(A|B) = \frac{P(B|A) \cdot P(A)}{P(B)}
\]</div>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(P(A|B)\)</span> is the posterior probability: the probability of the hypothesis A after observing B.</p></li>
<li><p><span class="math notranslate nohighlight">\(P(B|A)\)</span> is the likelihood: the probability of observing the evidence B given that hypothesis A is true.</p></li>
<li><p><span class="math notranslate nohighlight">\(P(A)\)</span> is the prior probability: the initial probability of the hypothesis A before observing B.</p></li>
<li><p><span class="math notranslate nohighlight">\(P(B)\)</span> is the evidence: the probability of observing the evidence B under all possible hypotheses.</p></li>
</ul>
</section>
<section id="conditional-probability">
<h2>Conditional Probability<a class="headerlink" href="#conditional-probability" title="Permalink to this heading">#</a></h2>
<p>Conditional probability represents the likelihood of an event or hypothesis occurring provided that another event has already occurred. In practice, this is important for calculating the likelihood <span class="math notranslate nohighlight">\(P(B|A)\)</span> – the probability of feature <span class="math notranslate nohighlight">\(B\)</span> given class <span class="math notranslate nohighlight">\(A\)</span>. This step is crucial in implementing the Naive Bayes algorithm because it allows us to update our beliefs about the probability of a hypothesis (such as a data point belonging to a certain class) based on the evidence present in the data.</p>
<p>The likelihood of an event given a condition can be defined mathematically as:</p>
<div class="math notranslate nohighlight">
\[
P(B|A) = \frac{P(A \cap B)}{P(A)}
\]</div>
<p>In the context of Naive Bayes:</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(P(B|A)\)</span> is the probability of observing the features <span class="math notranslate nohighlight">\(B\)</span> given that the class is <span class="math notranslate nohighlight">\(A\)</span>.</p></li>
<li><p><span class="math notranslate nohighlight">\(P(A \cap B)\)</span> represents the joint probability of class <span class="math notranslate nohighlight">\(A\)</span> occurring with feature <span class="math notranslate nohighlight">\(B\)</span>.</p></li>
<li><p><span class="math notranslate nohighlight">\(P(A)\)</span> is the probability of class <span class="math notranslate nohighlight">\(A\)</span> occurring.</p></li>
</ul>
<p>One of the assumptions of Naive Bayes is that all features <span class="math notranslate nohighlight">\(B_i\)</span> are conditionally independent given the class <span class="math notranslate nohighlight">\(A\)</span>. While in practice, this might not always be true, this simplification allows for the efficient computation of the posterior probability.</p>
</section>
<section id="interpretation">
<h2>Interpretation<a class="headerlink" href="#interpretation" title="Permalink to this heading">#</a></h2>
<p>This may seem intimidating at a glance, but most of these probabilities are available from a dataset through simple division. Our prior probabilities are just the count of data points with a certain trait divided by the total number of datapoints. For example:</p>
<section id="cat-size-vs-color">
<h3>Cat Size vs Color<a class="headerlink" href="#cat-size-vs-color" title="Permalink to this heading">#</a></h3>
<table class="table">
<thead>
<tr class="row-odd"><th class="head"><p></p></th>
<th class="head text-center"><p>large</p></th>
<th class="head text-center"><p>medium</p></th>
<th class="head text-center"><p>smol</p></th>
<th class="head"><p></p></th>
<th class="head text-center"><p>Totals</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p><strong>orange</strong></p></td>
<td class="text-center"><p>2</p></td>
<td class="text-center"><p>5</p></td>
<td class="text-center"><p>4</p></td>
<td><p></p></td>
<td class="text-center"><p>11</p></td>
</tr>
<tr class="row-odd"><td><p><strong>black</strong></p></td>
<td class="text-center"><p>3</p></td>
<td class="text-center"><p>6</p></td>
<td class="text-center"><p>6</p></td>
<td><p></p></td>
<td class="text-center"><p>15</p></td>
</tr>
<tr class="row-even"><td><p><strong>tabby</strong></p></td>
<td class="text-center"><p>4</p></td>
<td class="text-center"><p>7</p></td>
<td class="text-center"><p>1</p></td>
<td><p></p></td>
<td class="text-center"><p>12</p></td>
</tr>
<tr class="row-odd"><td><p></p></td>
<td class="text-center"><p></p></td>
<td class="text-center"><p></p></td>
<td class="text-center"><p></p></td>
<td><p></p></td>
<td class="text-center"><p></p></td>
</tr>
<tr class="row-even"><td><p><strong>Totals</strong></p></td>
<td class="text-center"><p>9</p></td>
<td class="text-center"><p>18</p></td>
<td class="text-center"><p>11</p></td>
<td><p></p></td>
<td class="text-center"><p>38</p></td>
</tr>
</tbody>
</table>
<p>Total cats: <span class="math notranslate nohighlight">\( 2 + 3 + 4 + 5 + 6 + 7 + 4 + 6 +1 = 38 \)</span>.</p>
<p>Total <strong>orange</strong> cats: <span class="math notranslate nohighlight">\( 2 + 5 + 4 = 11 \)</span>. <span class="math notranslate nohighlight">\( P(orange) = 11 / 38 = 0.289 \)</span>.</p>
<p>Total <strong>large</strong> cats: <span class="math notranslate nohighlight">\(2 + 3 + 4 = 9 \)</span>. <span class="math notranslate nohighlight">\( P(large) = 9 / 38 = 0.237 \)</span>.</p>
<p>What are the odds of a cat being large <strong>given that</strong> it’s an orange cat? Now the entire population is no longer all 38 cats, but only the 11 orange cats. <span class="math notranslate nohighlight">\(P(large|orange) = 2 / 11 = 0.181\)</span>.</p>
<p>The additional information that the cat is orange allows us to use a more specific probability than the odds derived from the entire dataset. This is conditional probability at work: Our data table provides that <span class="math notranslate nohighlight">\(orange \cap large = 2\)</span>.</p>
<p>Bayes’ Theorem is derived from conditional probability. we can use Bayes’ to calculate the inverse likelihood:</p>
<div class="math notranslate nohighlight">
\[ P(orange|large) = \frac{P(large|orange) \cdot P(orange)}{P(large)} = \frac{0.181 \cdot 0.289}{0.237} = 0.221 \]</div>
<p><em>Does that check out?</em> Just using conditional probability, we can determine that <span class="math notranslate nohighlight">\(P(orange|large) = 2 / 9 = 0.222 \)</span>. That’s what I get for working with only three decimal places.</p>
<p><em>Why use Bayes’, then?</em> We can calculate <span class="math notranslate nohighlight">\(P(size|color)\)</span> and <span class="math notranslate nohighlight">\(P(color|size)\)</span> for all the labels in this dataset from the table. We still need some likelihood (<span class="math notranslate nohighlight">\(P(large|orange)\)</span>) to use Bayes’, but it’s helpful in the situation of updating a hypothesis based on a new given: having learned that a cat is large, we can adjust the probabilities of each color.</p>
</section>
</section>
<section id="applications-and-examples">
<h2>Applications and Examples<a class="headerlink" href="#applications-and-examples" title="Permalink to this heading">#</a></h2>
<ol class="arabic simple">
<li><p><strong>Spam Filtering</strong>: One of the classic applications of the Naive Bayes Classifier is in distinguishing spam emails from legitimate ones. By analyzing the frequency and combinations of words in an email, the classifier assigns probabilities to the email being spam or not, effectively filtering out unwanted messages.</p></li>
<li><p><strong>Sentiment Analysis</strong>: Businesses utilize the Naive Bayes Classifier to gauge public sentiment from social media posts, reviews, and comments. This insight helps in understanding consumers’ perceptions of products or services, guiding strategic decisions.</p></li>
<li><p><strong>Medical Diagnosis</strong>: In healthcare, the Naive Bayes Classifier assists in diagnosing diseases by correlating symptoms with illnesses. By calculating the probabilities of various diseases given a set of symptoms, it supports medical professionals in making informed decisions.</p></li>
</ol>
<p>This lesson will guide you through the foundational theory of conditional probability and Bayes’ theorem, the mechanics of computing conditional likelihoods, and the practical steps to construct a Naive Bayes network using the pomegranate library. Through a blend of theoretical insights and hands-on exercises, we aim to foster a deep understanding of the Naive Bayes Classifier and its capabilities in solving classification challenges.</p>
</section>
<section id="develop-an-intuition-for-conditional-probability">
<h2>Develop An Intuition For Conditional Probability<a class="headerlink" href="#develop-an-intuition-for-conditional-probability" title="Permalink to this heading">#</a></h2>
<p>Let’s plot a mosaic chart, which uses proportional area to show the counts of events occurring together. The variables for this example will be “Playing Outside” (Yes or No), and “Weather” (Sunny, Cloudy, or Rainy).</p>
<p>Our dataset will cover 110 days: 40 sunny days, 30 rainy days, and 40 cloudy days. 55 of the days were “play” days, and 55 of the days were “no play” days. So without considering the weather, we have a 50% chance of playing outside. In other words, <span class="math notranslate nohighlight">\(P(play) = 50\%\)</span>.</p>
<p>But the variables are definitely connected, so if we know the weather we can give more specific odds on the chance of being able to play outside. We can calculate <span class="math notranslate nohighlight">\(P(play|sunny)\)</span>, <span class="math notranslate nohighlight">\(P(play|cloudy)\)</span> and <span class="math notranslate nohighlight">\(P(play|rainy)\)</span> by filtering and counting our data. We can visualize all these chances by plotting a mosaic that shows squares for all these different combinations.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Import necessary libraries</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">from</span> <span class="nn">statsmodels.graphics.mosaicplot</span> <span class="kn">import</span> <span class="n">mosaic</span>

<span class="c1"># Sample data: Weather Conditions vs. Playing a Sport</span>
<span class="c1"># This simulates a situation where the probability of playing a sport may depend on the weather condition.</span>
<span class="n">data</span> <span class="o">=</span> <span class="p">{</span>
    <span class="p">(</span><span class="s1">&#39;Sunny&#39;</span><span class="p">,</span> <span class="s1">&#39;Play&#39;</span><span class="p">):</span> <span class="mi">30</span><span class="p">,</span>
    <span class="p">(</span><span class="s1">&#39;Sunny&#39;</span><span class="p">,</span> <span class="s1">&#39;No Play&#39;</span><span class="p">):</span> <span class="mi">10</span><span class="p">,</span>
    <span class="p">(</span><span class="s1">&#39;Rainy&#39;</span><span class="p">,</span> <span class="s1">&#39;Play&#39;</span><span class="p">):</span> <span class="mi">5</span><span class="p">,</span>
    <span class="p">(</span><span class="s1">&#39;Rainy&#39;</span><span class="p">,</span> <span class="s1">&#39;No Play&#39;</span><span class="p">):</span> <span class="mi">25</span><span class="p">,</span>
    <span class="p">(</span><span class="s1">&#39;Cloudy&#39;</span><span class="p">,</span> <span class="s1">&#39;Play&#39;</span><span class="p">):</span> <span class="mi">20</span><span class="p">,</span>
    <span class="p">(</span><span class="s1">&#39;Cloudy&#39;</span><span class="p">,</span> <span class="s1">&#39;No Play&#39;</span><span class="p">):</span> <span class="mi">20</span><span class="p">,</span>
<span class="p">}</span>

<span class="c1"># Visualization</span>
<span class="n">mosaic</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">gap</span><span class="o">=</span><span class="mf">0.02</span><span class="p">,</span> <span class="n">title</span><span class="o">=</span><span class="s1">&#39;Conditional Probability: Weather Conditions vs. Playing a Sport&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Playing a Sport&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Weather Conditions&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>

<span class="c1"># Interpretation</span>
<span class="c1"># The mosaic plot visually represents the conditional relationships between the weather conditions and the decision to play a sport.</span>
<span class="c1"># The width of each block corresponds to the proportion of days with that particular weather condition,</span>
<span class="c1"># while the height of each section within the block represents the conditional probability of deciding to play or not play the sport, given the weather condition.</span>
<span class="c1"># For example, it&#39;s visually apparent that people are more likely to play on sunny days compared to rainy days.</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output traceback highlight-ipythontb notranslate"><div class="highlight"><pre><span></span><span class="gt">---------------------------------------------------------------------------</span>
<span class="ne">ModuleNotFoundError</span><span class="g g-Whitespace">                       </span>Traceback (most recent call last)
<span class="n">Cell</span> <span class="n">In</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">line</span> <span class="mi">4</span>
<span class="g g-Whitespace">      </span><span class="mi">2</span> <span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="g g-Whitespace">      </span><span class="mi">3</span> <span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="ne">----&gt; </span><span class="mi">4</span> <span class="kn">from</span> <span class="nn">statsmodels.graphics.mosaicplot</span> <span class="kn">import</span> <span class="n">mosaic</span>
<span class="g g-Whitespace">      </span><span class="mi">6</span> <span class="c1"># Sample data: Weather Conditions vs. Playing a Sport</span>
<span class="g g-Whitespace">      </span><span class="mi">7</span> <span class="c1"># This simulates a situation where the probability of playing a sport may depend on the weather condition.</span>
<span class="g g-Whitespace">      </span><span class="mi">8</span> <span class="n">data</span> <span class="o">=</span> <span class="p">{</span>
<span class="g g-Whitespace">      </span><span class="mi">9</span>     <span class="p">(</span><span class="s1">&#39;Sunny&#39;</span><span class="p">,</span> <span class="s1">&#39;Play&#39;</span><span class="p">):</span> <span class="mi">30</span><span class="p">,</span>
<span class="g g-Whitespace">     </span><span class="mi">10</span>     <span class="p">(</span><span class="s1">&#39;Sunny&#39;</span><span class="p">,</span> <span class="s1">&#39;No Play&#39;</span><span class="p">):</span> <span class="mi">10</span><span class="p">,</span>
   <span class="p">(</span><span class="o">...</span><span class="p">)</span>
<span class="g g-Whitespace">     </span><span class="mi">14</span>     <span class="p">(</span><span class="s1">&#39;Cloudy&#39;</span><span class="p">,</span> <span class="s1">&#39;No Play&#39;</span><span class="p">):</span> <span class="mi">20</span><span class="p">,</span>
<span class="g g-Whitespace">     </span><span class="mi">15</span> <span class="p">}</span>

<span class="ne">ModuleNotFoundError</span>: No module named &#39;statsmodels&#39;
</pre></div>
</div>
</div>
</div>
</section>
</section>
<section class="tex2jax_ignore mathjax_ignore" id="on-synthetic-data">
<h1>On Synthetic Data<a class="headerlink" href="#on-synthetic-data" title="Permalink to this heading">#</a></h1>
<p>Rather than provide a dataset, this next block of code will create a dataset based on certain parameters. This is very cool, because it allows us to imagine a population with specific parameters, sample it however we like, then run tests on the sampled data to try and recreate the parameters we created it with.</p>
<ul class="simple">
<li><p>Unlike real data, we’re able to objectively know the trends in the population, rather than simply measuring a model’s performance.</p></li>
<li><p>Synthetic data can be generated to mimic real-world data without containing any actual sensitive or personal information, making it invaluable for data sharing and public demonstrations.</p></li>
<li><p>It “compresses” well: the next paragraph of code can be used to produce millions of rows of data.</p></li>
</ul>
<p>When using synthetic data, try to think adversarially, too: what trends could you synthesize that would be difficult to analyze, or cause ambiguous results? Should every class label appear equally frequently in your samples? Never forget that <strong>synthetic data is not real data</strong>: Designing synthetic datasets that can challenge and reveal weaknesses in your models is a sophisticated task. It requires a deep understanding of both the domain and the potential pitfalls of data modeling, such as overfitting or underfitting to particular trends.</p>
<ul class="simple">
<li><p>A model performing well against synthetic data does not mean that model can be inherently trusted when applied to real data.</p></li>
<li><p>The trends you put into your data and the way you sample it can strongly bias the results that come out of it.</p></li>
</ul>
<p>With that out of the way, here is some data generated for today’s exercise, on the health impacts of smoking. <strong>The data generated has no real-world basis</strong>, if it demonstrates anything at all, it’s the author’s biases on the topic of cigarettes. Obviously, I advise you to not smoke cigarettes, but don’t use this completely confabulated dataset as your justification for that.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Synthetic data generation</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">random</span>

<span class="k">def</span> <span class="nf">random_row</span><span class="p">(</span><span class="n">chances_dict</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Generates a random row based on the provided chances for each tuple of smoker status and disease.</span>
<span class="sd">    Parameters:</span>
<span class="sd">        chances_dict (dict): A dictionary with keys as tuples of (smoker status, disease) and values as the chance of each.</span>
<span class="sd">    Returns:</span>
<span class="sd">        dict: A dictionary representing a single row with &#39;smoker&#39; and &#39;disease&#39; keys.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># Normalize the chances to ensure they sum to 1</span>
    <span class="n">total_chance</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">(</span><span class="n">chances_dict</span><span class="o">.</span><span class="n">values</span><span class="p">())</span>
    <span class="n">normalized_chances</span> <span class="o">=</span> <span class="p">{</span><span class="n">key</span><span class="p">:</span> <span class="n">value</span> <span class="o">/</span> <span class="n">total_chance</span> <span class="k">for</span> <span class="n">key</span><span class="p">,</span> <span class="n">value</span> <span class="ow">in</span> <span class="n">chances_dict</span><span class="o">.</span><span class="n">items</span><span class="p">()}</span>
    
    <span class="c1"># Choose a random tuple based on the chances</span>
    <span class="n">chosen_tuple</span> <span class="o">=</span> <span class="n">random</span><span class="o">.</span><span class="n">choices</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="n">normalized_chances</span><span class="o">.</span><span class="n">keys</span><span class="p">()),</span> <span class="n">weights</span><span class="o">=</span><span class="n">normalized_chances</span><span class="o">.</span><span class="n">values</span><span class="p">(),</span> <span class="n">k</span><span class="o">=</span><span class="mi">1</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
    
    <span class="c1"># Return the chosen tuple as a dictionary</span>
    <span class="k">return</span> <span class="p">{</span><span class="s1">&#39;smoker&#39;</span><span class="p">:</span> <span class="n">chosen_tuple</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="s1">&#39;disease&#39;</span><span class="p">:</span> <span class="n">chosen_tuple</span><span class="p">[</span><span class="mi">1</span><span class="p">]}</span>

<span class="k">def</span> <span class="nf">create_smoker_csv</span><span class="p">(</span><span class="n">num_rows</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Creates a CSV file with data generated from random_row function.</span>
<span class="sd">    </span>
<span class="sd">    Parameters:</span>
<span class="sd">        num_rows (int): Number of rows to generate.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># Define the chances dictionary for generating rows</span>
    <span class="n">chances_dict</span> <span class="o">=</span> <span class="p">{</span>
        <span class="p">(</span><span class="s2">&quot;never smoked&quot;</span><span class="p">,</span> <span class="s2">&quot;healthy&quot;</span><span class="p">):</span> <span class="mf">0.35</span><span class="p">,</span>
        <span class="p">(</span><span class="s2">&quot;never smoked&quot;</span><span class="p">,</span> <span class="s2">&quot;bronchitis&quot;</span><span class="p">):</span> <span class="mf">0.05</span><span class="p">,</span>
        <span class="p">(</span><span class="s2">&quot;never smoked&quot;</span><span class="p">,</span> <span class="s2">&quot;cancer&quot;</span><span class="p">):</span> <span class="mf">0.02</span><span class="p">,</span>
        <span class="p">(</span><span class="s2">&quot;never smoked&quot;</span><span class="p">,</span> <span class="s2">&quot;both&quot;</span><span class="p">):</span> <span class="mf">0.01</span><span class="p">,</span>
        <span class="p">(</span><span class="s2">&quot;quit smoking&quot;</span><span class="p">,</span> <span class="s2">&quot;healthy&quot;</span><span class="p">):</span> <span class="mf">0.25</span><span class="p">,</span>
        <span class="p">(</span><span class="s2">&quot;quit smoking&quot;</span><span class="p">,</span> <span class="s2">&quot;bronchitis&quot;</span><span class="p">):</span> <span class="mf">0.1</span><span class="p">,</span>
        <span class="p">(</span><span class="s2">&quot;quit smoking&quot;</span><span class="p">,</span> <span class="s2">&quot;cancer&quot;</span><span class="p">):</span> <span class="mf">0.05</span><span class="p">,</span>
        <span class="p">(</span><span class="s2">&quot;quit smoking&quot;</span><span class="p">,</span> <span class="s2">&quot;both&quot;</span><span class="p">):</span> <span class="mf">0.02</span><span class="p">,</span>
        <span class="p">(</span><span class="s2">&quot;current smoker&quot;</span><span class="p">,</span> <span class="s2">&quot;healthy&quot;</span><span class="p">):</span> <span class="mf">0.1</span><span class="p">,</span>
        <span class="p">(</span><span class="s2">&quot;current smoker&quot;</span><span class="p">,</span> <span class="s2">&quot;bronchitis&quot;</span><span class="p">):</span> <span class="mf">0.07</span><span class="p">,</span>
        <span class="p">(</span><span class="s2">&quot;current smoker&quot;</span><span class="p">,</span> <span class="s2">&quot;cancer&quot;</span><span class="p">):</span> <span class="mf">0.02</span><span class="p">,</span>
        <span class="p">(</span><span class="s2">&quot;current smoker&quot;</span><span class="p">,</span> <span class="s2">&quot;both&quot;</span><span class="p">):</span> <span class="mf">0.01</span>
    <span class="p">}</span>
    
    <span class="c1"># Generate data</span>
    <span class="n">data</span> <span class="o">=</span> <span class="p">[</span><span class="n">random_row</span><span class="p">(</span><span class="n">chances_dict</span><span class="p">)</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_rows</span><span class="p">)]</span>
    
    <span class="c1"># Convert to DataFrame and write to CSV</span>
    <span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
    <span class="n">df</span><span class="o">.</span><span class="n">to_csv</span><span class="p">(</span><span class="s1">&#39;health_dataset.csv&#39;</span><span class="p">,</span> <span class="n">index</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

<span class="c1"># Example usage to create a CSV file with 1000 rows</span>
<span class="n">create_smoker_csv</span><span class="p">(</span><span class="mi">1000</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</section>
<section class="tex2jax_ignore mathjax_ignore" id="constructing-a-naive-bayes-classifier-with-pomegranate">
<h1>Constructing a Naive Bayes Classifier with pomegranate<a class="headerlink" href="#constructing-a-naive-bayes-classifier-with-pomegranate" title="Permalink to this heading">#</a></h1>
<p>After delving into the theory behind the Naive Bayes Classifier and exploring its diversified applications, it’s time to translate this theoretical knowledge into practice. Leveraging the <code class="docutils literal notranslate"><span class="pre">pomegranate</span></code> library, this part of the lesson focuses on the technical steps necessary to construct, train, and employ a Naive Bayes classifier in addressing a real-world classification challenge. The <code class="docutils literal notranslate"><span class="pre">pomegranate</span></code> library has been chosen for its user-friendly interface and efficient computation capabilities which streamline the process of building probabilistic models.</p>
<section id="exercise-for-the-reader">
<h2>Exercise For The Reader<a class="headerlink" href="#exercise-for-the-reader" title="Permalink to this heading">#</a></h2>
<p>In this exercise, you are provided with a dataset named <code class="docutils literal notranslate"><span class="pre">health_dataset.csv</span></code>, which comprises patient records. Each record includes attributes such as <code class="docutils literal notranslate"><span class="pre">Age</span></code>, <code class="docutils literal notranslate"><span class="pre">Gender</span></code>, <code class="docutils literal notranslate"><span class="pre">BMI</span></code>, <code class="docutils literal notranslate"><span class="pre">Smoker</span></code>, and <code class="docutils literal notranslate"><span class="pre">Disease</span></code>. Your task is to apply the concepts of the Naive Bayes Classifier introduced in the lesson to this real-world dataset. The objective is to compute conditional probabilities, visualize relationships between variables, and ultimately, predict the likelihood of a patient having a certain disease based on their characteristics.</p>
<section id="definition">
<h3>Definition<a class="headerlink" href="#definition" title="Permalink to this heading">#</a></h3>
<p>Recall the core concept behind the Naive Bayes Classifier: it is based on Bayes’ theorem, which relates the conditional probabilities of events. The theorem is mathematically represented as:</p>
<div class="math notranslate nohighlight">
\[
P(Disease|Features) = \frac{P(Features|Disease) \cdot P(Disease)}{P(Features)}
\]</div>
<p>In this formula, <span class="math notranslate nohighlight">\(P(Disease|Features)\)</span> is the posterior probability of having a disease given the patient features, <span class="math notranslate nohighlight">\(P(Features|Disease)\)</span> is the likelihood of observing these features given the disease, <span class="math notranslate nohighlight">\(P(Disease)\)</span> is the prior probability of the disease, and <span class="math notranslate nohighlight">\(P(Features)\)</span> is the probability of the features.</p>
</section>
<section id="task-workflow">
<h3>Task Workflow:<a class="headerlink" href="#task-workflow" title="Permalink to this heading">#</a></h3>
<ol class="arabic simple">
<li><p><strong>Load the Dataset</strong>: Begin by loading <code class="docutils literal notranslate"><span class="pre">health_dataset.csv</span></code> into a pandas DataFrame. This dataset serves as the foundation for your computations and analyses.</p></li>
<li><p><strong>Data Exploration</strong>: Familiarize yourself with the dataset. Compute basic statistics, and explore the distribution of each feature and the target variable <code class="docutils literal notranslate"><span class="pre">Disease</span></code>. Understanding the structure and characteristics of your data is crucial.</p></li>
<li><p><strong>Conditional Probability Calculations</strong>: Use the <code class="docutils literal notranslate"><span class="pre">bayes_given</span></code> function to filter the dataset based on certain conditions (e.g., <code class="docutils literal notranslate"><span class="pre">smoker</span> <span class="pre">=</span> <span class="pre">current</span> <span class="pre">smoker</span></code>). Compute conditional probabilities such as <span class="math notranslate nohighlight">\(P(Disease|Smoker)\)</span> and <span class="math notranslate nohighlight">\(P(Disease|BMI&gt;25)\)</span>. This step is key to understanding how individual features relate to the likelihood of the disease.</p></li>
<li><p><strong>Visualization</strong>: Create mosaic plots to visually represent the relationships between features (e.g., <code class="docutils literal notranslate"><span class="pre">smoker</span></code>) and the target variable <code class="docutils literal notranslate"><span class="pre">Disease</span></code>. Visualizations help in intuitively grasping how various factors influence the probability of diseases.</p></li>
<li><p><strong>Interpretation</strong>: Interpret the calculated probabilities and visualizations to draw conclusions about the relationship between patient features and the likelihood of having a disease. Consider how this exercise reflects the practical application of the Naive Bayes Classifier in identifying patterns and predicting outcomes based on probabilities.</p></li>
</ol>
<p>Good luck!</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Import necessary libraries</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">from</span> <span class="nn">statsmodels.graphics.mosaicplot</span> <span class="kn">import</span> <span class="n">mosaic</span>

<span class="c1"># Load the dataset</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">&#39;health_dataset.csv&#39;</span><span class="p">)</span>

<span class="c1"># Explore the dataset</span>
<span class="c1"># Print basic statistics</span>
<span class="nb">print</span><span class="p">(</span><span class="n">df</span><span class="o">.</span><span class="n">describe</span><span class="p">())</span>
<span class="c1"># Print the distribution of the target variable &#39;Disease&#39;</span>
<span class="nb">print</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;disease&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">value_counts</span><span class="p">())</span>

<span class="c1"># Data Filtering Function</span>
<span class="k">def</span> <span class="nf">bayes_given</span><span class="p">(</span><span class="n">condition</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Filters the dataset based on a given condition and calculates probabilities relevant for Naive Bayes.</span>
<span class="sd">    </span>
<span class="sd">    Parameters:</span>
<span class="sd">        condition (dict): A dictionary where keys are column names and values are conditions on those columns.</span>
<span class="sd">    </span>
<span class="sd">    Returns:</span>
<span class="sd">        float: Conditional probabilities based on the filter applied.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># Apply filter based on condition</span>
    <span class="c1"># For example, condition could be {&#39;Smoker&#39;: &#39;Yes&#39;}</span>
    <span class="n">filtered_df</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>  <span class="c1"># Start with a copy of the original DataFrame</span>
    
    <span class="k">for</span> <span class="n">column</span><span class="p">,</span> <span class="n">value</span> <span class="ow">in</span> <span class="n">condition</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
        <span class="c1"># Here, implement filtering based on condition, e.g.,</span>
        <span class="c1"># if column == &#39;Smoker&#39; and value == &#39;Yes&#39;:</span>
        <span class="n">filtered_df</span> <span class="o">=</span> <span class="n">filtered_df</span><span class="p">[</span><span class="n">filtered_df</span><span class="p">[</span><span class="n">column</span><span class="p">]</span> <span class="o">==</span> <span class="n">value</span><span class="p">]</span>
    
    <span class="c1"># Calculate and return conditional probability</span>
    <span class="c1"># Placeholder for conditional probability calculation</span>
    <span class="c1"># Example: prob_disease_given_condition = (number of diseased in filtered_df) / (total number in filtered_df)</span>
    <span class="n">prob_disease_given_condition</span> <span class="o">=</span> <span class="mf">0.0</span>  <span class="c1"># Placeholder, replace with actual calculation</span>
    
    <span class="k">return</span> <span class="n">prob_disease_given_condition</span>

<span class="c1"># Example of how to use the bayes_given function</span>
<span class="c1"># This is just a template, you will need to fill in the actual logic</span>
<span class="n">condition_example</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;smoker&#39;</span><span class="p">:</span> <span class="s1">&#39;never smoked&#39;</span><span class="p">}</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Conditional probability (placeholder) for condition </span><span class="si">{</span><span class="n">condition_example</span><span class="si">}</span><span class="s2">:&quot;</span><span class="p">,</span>
      <span class="n">bayes_given</span><span class="p">(</span><span class="n">condition_example</span><span class="p">))</span>

<span class="c1"># Visualization - Mosaic Plot (Placeholder)</span>
<span class="c1"># You should replace the zeros with the appropriate variables from your calculations</span>
<span class="n">mosaic</span><span class="p">(</span><span class="n">df</span><span class="p">,</span> <span class="p">[</span><span class="s1">&#39;smoker&#39;</span><span class="p">,</span> <span class="s1">&#39;disease&#39;</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Mosaic Plot of Smoker vs. Disease&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>

<span class="c1"># Interpretation</span>
<span class="c1"># At this stage, you would interpret the results from your calculations and visualizations.</span>
<span class="c1"># For example, you could discuss how the conditional probabilities and mosaic plot reflect the likelihood of disease given certain conditions.</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output traceback highlight-ipythontb notranslate"><div class="highlight"><pre><span></span><span class="gt">---------------------------------------------------------------------------</span>
<span class="ne">ModuleNotFoundError</span><span class="g g-Whitespace">                       </span>Traceback (most recent call last)
<span class="n">Cell</span> <span class="n">In</span><span class="p">[</span><span class="mi">3</span><span class="p">],</span> <span class="n">line</span> <span class="mi">4</span>
<span class="g g-Whitespace">      </span><span class="mi">2</span> <span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="g g-Whitespace">      </span><span class="mi">3</span> <span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="ne">----&gt; </span><span class="mi">4</span> <span class="kn">from</span> <span class="nn">statsmodels.graphics.mosaicplot</span> <span class="kn">import</span> <span class="n">mosaic</span>
<span class="g g-Whitespace">      </span><span class="mi">6</span> <span class="c1"># Load the dataset</span>
<span class="g g-Whitespace">      </span><span class="mi">7</span> <span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">&#39;health_dataset.csv&#39;</span><span class="p">)</span>

<span class="ne">ModuleNotFoundError</span>: No module named &#39;statsmodels&#39;
</pre></div>
</div>
</div>
</div>
<p>Good luck and happy analyzing!</p>
</section>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./Week_06"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

                </article>
              

              
              
              
              
                <footer class="prev-next-footer">
                  
<div class="prev-next-area">
    <a class="left-prev"
       href="Lesson_29.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title">Day 29: Introduction to Decision Trees</p>
      </div>
    </a>
    <a class="right-next"
       href="../Week_07/007_Overview.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">Course Structure</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">

  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#">Introduction to Naive Bayes Classifier</a><ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#understanding-bayes-theorem-and-conditional-probability">Understanding Bayes’ Theorem and Conditional Probability</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#conditional-probability">Conditional Probability</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#interpretation">Interpretation</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#cat-size-vs-color">Cat Size vs Color</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#applications-and-examples">Applications and Examples</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#develop-an-intuition-for-conditional-probability">Develop An Intuition For Conditional Probability</a></li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#on-synthetic-data">On Synthetic Data</a></li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#constructing-a-naive-bayes-classifier-with-pomegranate">Constructing a Naive Bayes Classifier with pomegranate</a><ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#exercise-for-the-reader">Exercise For The Reader</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#definition">Definition</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#task-workflow">Task Workflow:</a></li>
</ul>
</li>
</ul>
</li>
</ul>

  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By Aaron S. & John M.
</p>

  </div>
  
  <div class="footer-item">
    

  <p class="copyright">
    
      © Copyright 2023.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../_static/scripts/bootstrap.js?digest=5b4479735964841361fd"></script>
<script src="../_static/scripts/pydata-sphinx-theme.js?digest=5b4479735964841361fd"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>